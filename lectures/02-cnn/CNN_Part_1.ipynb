{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN. Part 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn8ilyMiMMEX",
        "colab_type": "text"
      },
      "source": [
        "# Сверточные нейронные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y0cfIJqNQHx",
        "colab_type": "text"
      },
      "source": [
        "## Что такое сверточный слой?\n",
        "\n",
        "Сверточный слой - более упрощенный слой, который позволяет сократить количество параметров сети. Важной особенностью слоя является то, что производится операция свертки слоя c набором весов. \n",
        "\n",
        "Формально, математическая модель определена следующим образом:\n",
        "\n",
        "рассмотрим двумерный канал изображения размером $W \\times H$, определим сверточный слой с ядром размера $K \\times K$ как операцию свертки для каждого квадрата размером $K \\times K$ с матрицей весов.\n",
        "\n",
        "Параметры сверточного слоя:\n",
        "\n",
        "* количество входных фильтров - $in$\n",
        "* количество выходных фильтров - $out$.\n",
        "\n",
        "Для каждого фильтра для пикселя выход определяется следующим образом:\n",
        "\n",
        "$$\n",
        "   out_{i,j} = \\sum_{s = -[(k-1)/2]}^{[k/2]} \\sum_{t=-[(k-1)/2]}^{[k/2]} W_{s, t} I_{i +s, j + t} + b,\n",
        "$$\n",
        "\n",
        "где $W$ - матрица весов для фильтра, $b$ - смещение (bias), $I$ - фильтр (двумерный массив размера $W \\times H$), к которому применяется свертка.\n",
        "\n",
        "**Вопрос**. Какое количество тренируемых параметров используется в сверточном слое?\n",
        "\n",
        "**Ответ** $(K \\times K + 1) \\times in \\times out$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu_lZbDquH83",
        "colab_type": "text"
      },
      "source": [
        "## Дополнительные параметры сверточного слоя\n",
        "\n",
        "Дополнительно необходимо определить следующие параметры сверточного слоя:\n",
        "* stride - шаг, с каким производится свертка\n",
        "* padding - начальное и конечное положение, с которого начинается свертка.\n",
        "\n",
        "**Вопрос.** Какой будет размер выходного фильтра, если используется свертка с ядром $K \\times K$, stride - (1, 1), начало и конец находятся в вершинах изображения?\n",
        "\n",
        "**Ответ.** $ (W - K + 1) \\times (H - K + 1)$.\n",
        "\n",
        "Чтобы размер фильтра не менялся, применяется следующая стратегия: входной фильтр дополняется нулями таким образом, чтобы размер выходного слоя был $W \\times H$. Такая стратегия называется same padding. Изначальная стратегия называется valid padding.\n",
        "\n",
        "Приступим к реализации сверточного слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuM2w5OdNTdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def conv2d_one_filter(X, W, padding='same', stride=(1, 1)):\n",
        "    \"\"\"\n",
        "        @param X: input image, [w \\times h]\n",
        "        @param W: weights, [K \\times K]\n",
        "        @param padding: padding type - same or full\n",
        "    \"\"\"\n",
        "    \n",
        "    kernel_y, kernel_x = W.shape[:2]\n",
        "    \n",
        "    # Calculating shape of new pad\n",
        "    \n",
        "    if padding == 'same':\n",
        "        y_shape = X.shape[0] + kernel_y - 1\n",
        "        x_shape = X.shape[1] + kernel_x - 1\n",
        "    else:\n",
        "        y_shape, x_shape = X.shape[:2]\n",
        "    \n",
        "    x_padded = np.zeros((y_shape, x_shape), dtype=X.dtype)\n",
        "    print(x_padded.shape)\n",
        "    \n",
        "    if padding == 'valid':\n",
        "        padding_left = 0\n",
        "        padding_top = 0\n",
        "    else:\n",
        "        padding_left = (kernel_x - 1) // 2\n",
        "        padding_top = (kernel_y - 1) // 2\n",
        "    \n",
        "    x_padded[\n",
        "        padding_top:padding_top + X.shape[0],\n",
        "        padding_left:padding_left + X.shape[1]\n",
        "    ] = X\n",
        "\n",
        "    result = np.zeros((x_padded.shape[0] - kernel_y + 1, x_padded.shape[1] - kernel_x + 1))\n",
        "    \n",
        "    for y in range(x_padded.shape[0]):\n",
        "        for x in range(x_padded.shape[1]):\n",
        "            if y + kernel_y > x_padded.shape[0] or x + kernel_x > x_padded.shape[1]:\n",
        "                continue\n",
        "            result[y, x] = np.sum(x_padded[y:y + kernel_y, x:x + kernel_x] * W)\n",
        "    return result\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHe6XxUXw1KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.signal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUOul874ywqk",
        "colab_type": "code",
        "outputId": "2c7759cd-0bf7-401a-c0eb-faa8e023fad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!nproc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE64oiFUw2T8",
        "colab_type": "code",
        "outputId": "b7fbf417-e7ee-4a8d-fbc6-265333093a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "conv2d_one_filter(np.array([\n",
        "   [1, 2, 3],\n",
        "   [4, 5, 6],\n",
        "   [7, 8, 9]\n",
        "]), np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 94., 154., 106.],\n",
              "       [186., 285., 186.],\n",
              "       [106., 154.,  94.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkYNiro7yOJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaY1ruOIz8p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "a = tf.placeholder(tf.float32, [1, 3, 3, 1])\n",
        "w = tf.placeholder(tf.float32, [3, 3, 1, 1])\n",
        "out_same = tf.nn.conv2d(a, w, padding='SAME')\n",
        "out_valid = tf.nn.conv2d(a, w, padding='VALID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99vctnk70ZoY",
        "colab_type": "code",
        "outputId": "5b788917-fb54-47c4-d62d-e1db274320bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sess.run(out_same, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "    w: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((3, 3, 1, 1))\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 94.],\n",
              "         [154.],\n",
              "         [106.]],\n",
              "\n",
              "        [[186.],\n",
              "         [285.],\n",
              "         [186.]],\n",
              "\n",
              "        [[106.],\n",
              "         [154.],\n",
              "         [ 94.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VKhVVmE0oqA",
        "colab_type": "code",
        "outputId": "db33465e-4ddf-4832-dbb7-0e8d4cbc3092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess.run(out_valid, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "    w: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((3, 3, 1, 1))\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[285.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ3A6rr60iDS",
        "colab_type": "text"
      },
      "source": [
        "##  Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItaQ6X_vANp7",
        "colab_type": "text"
      },
      "source": [
        "Pooling - операция, которая позволяет аггрегировать информацию по некоторому фильтру. Примеры pooling-слоев:\n",
        "* max pooling - вычисляет максимальное значение в ядре\n",
        "* average pooling - вычисляет среднее значение в ядре\n",
        "\n",
        "Является одним из способов снижения размерности:\n",
        "\n",
        "Если взять max pooling с ядром $2 \\times 2$ и с шагом по каждой оси $2 \\times 2$, то как изменится размер выходного тензора?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZYNNqjr1QQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.placeholder(tf.float32, (1, 3, 3, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54mtRlzc1Vop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pool_valid = tf.nn.max_pool2d(a, ksize=(2, 2), strides=(1, 1), padding='VALID')\n",
        "pool_same = tf.nn.max_pool2d(a, ksize=(2, 2), strides=(1, 1), padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xqnRR-c1Y_Z",
        "colab_type": "code",
        "outputId": "5d27fac4-762d-42d1-d284-c4647e8890b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sess.run(pool_valid, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[5.],\n",
              "         [6.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNcPUMsd1aAI",
        "colab_type": "code",
        "outputId": "695a847e-cde3-4d18-b144-7955928189d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sess.run(pool_same, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[5.],\n",
              "         [6.],\n",
              "         [6.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.],\n",
              "         [9.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.],\n",
              "         [9.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rtWJyJT2tgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBJya11N13PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pooling(X, kernel_size=(2, 2), padding='same', strides=(2, 2)):\n",
        "    height, width = X.shape[:2]\n",
        "    if padding == 'same':\n",
        "        out_height = math.ceil(height / strides[0])\n",
        "        out_width = math.ceil(width / strides[1])\n",
        "    else:\n",
        "        out_height = (height - kernel_size[0] + 1) // strides[0]\n",
        "        out_width = (width - kernel_size[1] + 1) // strides[1]\n",
        "    \n",
        "    result = np.zeros((out_height, out_width), dtype=X.dtype)\n",
        "    \n",
        "    for y in range(out_height):\n",
        "        for x in range(out_width):\n",
        "            start_y = y * strides[0]\n",
        "            start_x = x * strides[1]\n",
        "            \n",
        "            result[y, x] = np.max(\n",
        "                X[\n",
        "                    start_y:start_y + kernel_size[0],\n",
        "                    start_x:start_x + kernel_size[1]\n",
        "                ]\n",
        "            )\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQbwem4h4NkA",
        "colab_type": "code",
        "outputId": "0fcabb59-d798-4793-8fdb-f4d031b75a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 6],\n",
              "       [8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoNpdzQ44T3v",
        "colab_type": "code",
        "outputId": "efec79f0-484d-4f20-c12b-c86959bb93c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]),\n",
        "    padding='valid'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6N1Kwbk4WpP",
        "colab_type": "code",
        "outputId": "305841d8-0700-48be-ddc0-8561c824ec5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]),\n",
        "    padding='valid',\n",
        "    strides=(1, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 6],\n",
              "       [8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cet0I6d4ZVX",
        "colab_type": "code",
        "outputId": "f87941d9-eac3-4771-a52c-84151f6700e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]),\n",
        "    padding='same',\n",
        "    strides=(1, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 6, 6],\n",
              "       [8, 9, 9],\n",
              "       [8, 9, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYt-zwnDK5jg",
        "colab_type": "text"
      },
      "source": [
        "## Базовые блоки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqQE9YAx5eJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "def conv_layer(\n",
        "        input_tensor,\n",
        "        output_channels,\n",
        "        name='conv',\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='SAME'\n",
        "    ):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        input_shape = input_tensor.get_shape().as_list()\n",
        "        \n",
        "        input_channels = input_shape[-1]\n",
        "        \n",
        "        print(input_channels, output_channels)\n",
        "        \n",
        "        weights = tf.get_variable(name='weights', shape=[\n",
        "            kernel_size[0], kernel_size[1], input_channels, output_channels\n",
        "        ])\n",
        "        \n",
        "        bias = tf.get_variable(\n",
        "            name='bias',\n",
        "            shape=[output_channels],\n",
        "            initializer=tf.zeros_initializer()\n",
        "        )\n",
        "        \n",
        "        conv = tf.nn.conv2d(\n",
        "            input=input_tensor,\n",
        "            filter=weights,\n",
        "            strides=strides,\n",
        "            padding=padding,\n",
        "            name='conv'\n",
        "        )\n",
        "        \n",
        "        output = tf.nn.bias_add(conv, bias, name='output')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zucgYvJtK_o8",
        "colab_type": "code",
        "outputId": "be54214d-6e4e-4aa6-a160-c4540f256375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "a = tf.placeholder(tf.float32, (1, 3, 3, 1))\n",
        "b = conv_layer(a, 3)\n",
        "example = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).reshape((1, 3, 3, 1))\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b, feed_dict={\n",
        "    a: example\n",
        "})"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-0.76100045, -2.3675907 ,  1.2371047 ],\n",
              "         [-0.49668634, -1.8237138 ,  0.9400004 ],\n",
              "         [-1.4553041 , -0.72431755,  1.2220502 ]],\n",
              "\n",
              "        [[-1.4469042 , -5.3037224 ,  2.486132  ],\n",
              "         [-0.28262454, -3.467764  ,  2.2337024 ],\n",
              "         [-1.0618773 , -2.0336287 ,  3.0898426 ]],\n",
              "\n",
              "        [[ 0.5349655 , -5.1479397 ,  1.8384641 ],\n",
              "         [ 2.3510103 , -4.6678867 ,  4.5698705 ],\n",
              "         [ 2.1267679 , -2.318857  ,  4.3377833 ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFAY4gMLF0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pool(\n",
        "    input_tensor,\n",
        "    kernel_size=(2, 2),\n",
        "    strides=(2, 2),\n",
        "    padding='SAME',\n",
        "    name='pool'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        output = tf.nn.max_pool2d(input_tensor, ksize=kernel_size, strides=strides, padding=padding, name='pool')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayeICMKSbvmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def avg_pool(\n",
        "    input_tensor,\n",
        "    kernel_size=(2, 2),\n",
        "    strides=(2, 2),\n",
        "    padding='SAME',\n",
        "    name='pool'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        output = tf.nn.avg_pool2d(input_tensor, ksize=kernel_size, strides=strides, padding=padding, name='pool')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOyKj4h7MCEN",
        "colab_type": "code",
        "outputId": "05481c67-5e82-4269-e862-764d9b76bec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "a = tf.placeholder(tf.float32, (1, 3, 3, 1))\n",
        "b = max_pool(a)\n",
        "example = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).reshape((1, 3, 3, 1))\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b, feed_dict={\n",
        "    a: example\n",
        "})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[5.],\n",
              "         [6.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb0b_cQZ1STL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(\n",
        "    input_tensor,\n",
        "    name='flatten'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        shape = input_tensor.get_shape().as_list()[1:]\n",
        "        num_elements = np.prod(shape)\n",
        "        return tf.reshape(input_tensor, [-1, num_elements], name='reshape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw9fQKqU1-2G",
        "colab_type": "code",
        "outputId": "42651188-5f00-490e-9a00-6b4bae91c48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "a = tf.zeros([1, 3, 3, 1])\n",
        "b = flatten(a)\n",
        "sess.run(b)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCu9X5fj2Hxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense(\n",
        "    input_tensor,\n",
        "    output_neurons,\n",
        "    name='fc'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        input_neurons = input_tensor.get_shape().as_list()[1]\n",
        "        \n",
        "        weights = tf.get_variable(\n",
        "            name='weights',\n",
        "            shape=[input_neurons, output_neurons]\n",
        "        )\n",
        "        \n",
        "        bias = tf.get_variable(\n",
        "            name='bias',\n",
        "            shape=[output_neurons]\n",
        "        )\n",
        "        \n",
        "        product = tf.matmul(input_tensor, weights, name='product')\n",
        "        \n",
        "        output = tf.nn.bias_add(product, bias, name='output')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZh2Ho_G3EMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.zeros([1, 9])\n",
        "b = dense(a, 18, name='fc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYGBvW6_3JkZ",
        "colab_type": "code",
        "outputId": "939a5fd3-df89-4111-e485-e18208d4c3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07266536,  0.04110315, -0.06682327, -0.08272639,  0.18806207,\n",
              "         0.033252  ,  0.4061237 ,  0.15455014,  0.35857058, -0.31745896,\n",
              "         0.09687263, -0.15119013,  0.16809756, -0.25666726,  0.05608675,\n",
              "         0.25709748,  0.07112962, -0.39342153]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f59keuqT4bvm",
        "colab_type": "text"
      },
      "source": [
        "##Архитектуры сетей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1XGQeK5Hrd",
        "colab_type": "text"
      },
      "source": [
        "### LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzxeau5d3SSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(\n",
        "    x,\n",
        "    output_channels,\n",
        "    name,\n",
        "    strides=(1, 1),\n",
        "    kernel_size=(3, 3),\n",
        "    padding='SAME'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        conv_out = conv_layer(x, output_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=padding,\n",
        "            strides=strides\n",
        "        )\n",
        "        activation = tf.nn.relu(conv_out, name='relu')\n",
        "    return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiJ-D0Ww3-By",
        "colab_type": "code",
        "outputId": "0506f023-c1b7-436f-986d-c5a5b3b04095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "a = tf.zeros((1, 3, 3, 1))\n",
        "b = conv_block(a, 6, 'conv1')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IjnuWs4fHK",
        "colab_type": "code",
        "outputId": "138957eb-134e-4b64-a007-de806ee87a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3, 3, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy3B_3FT4wM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def le_net(input_tensor):\n",
        "    with tf.variable_scope('le_net', reuse=tf.AUTO_REUSE):\n",
        "        conv1_out = conv_block(\n",
        "            input_tensor, 6,\n",
        "            name='conv1',\n",
        "            kernel_size=(5, 5),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        pool1_out = max_pool(conv1_out, name='pool1')\n",
        "        conv2_out = conv_block(\n",
        "            pool1_out, 16,\n",
        "            name='conv2',\n",
        "            kernel_size=(5, 5),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        \n",
        "        pool2_out = max_pool(conv2_out, name='pool2')\n",
        "        \n",
        "        flatten_out = flatten(pool2_out)\n",
        "        \n",
        "        fc1_out = dense(flatten_out, 120, name='fc1')\n",
        "        fc2_out = dense(fc1_out, 84, name='fc2')\n",
        "        \n",
        "        output = dense(fc2_out, 10, name='fc3')\n",
        "    return output\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY0ah_3_6v26",
        "colab_type": "code",
        "outputId": "ae7d1731-c28d-44e9-b7cb-b0eaf8d1f927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "digits_placeholder = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
        "logits = le_net(digits_placeholder)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 6\n",
            "6 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqOCKdLqxY5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_placeholder = tf.placeholder(tf.float32, [None, 10], name='le_net_labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CNXR58_xkcN",
        "colab_type": "code",
        "outputId": "7afd00ae-7bc4-44af-abf6-d7b8d00a0033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    labels=labels_placeholder,\n",
        "    logits=logits\n",
        ")\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipubrdsxwGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='le_net')\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss, var_list=le_net_trainable_variables)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QpPR2KaWeyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_predictions = tf.argmax(logits, axis=1)\n",
        "le_net_target = tf.argmax(labels_placeholder, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhhGoXkBQQAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_metrics(scope_name, variables: dict):\n",
        "    with tf.name_scope(f'{scope_name}train/'):\n",
        "        accuracy_train, accuracy_train_op = tf.metrics.accuracy(\n",
        "            labels=variables['target'],\n",
        "            predictions=variables['predictions']\n",
        "        )\n",
        "        loss_train, loss_train_op = tf.metrics.mean(\n",
        "            values=variables['loss'],\n",
        "            name='loss'\n",
        "        )\n",
        "    with tf.name_scope(f'{scope_name}val/'):\n",
        "        accuracy_val, accuracy_val_op = tf.metrics.accuracy(\n",
        "            labels=variables['target'],\n",
        "            predictions=variables['predictions']\n",
        "        )\n",
        "        loss_val, loss_val_op = tf.metrics.mean(\n",
        "            values=variables['loss'],\n",
        "            name='loss'\n",
        "        )\n",
        "    \n",
        "    return {\n",
        "        'train_acc': accuracy_train,\n",
        "        'train_update_acc': accuracy_train_op,\n",
        "        'val_acc': accuracy_val,\n",
        "        'val_update_acc': accuracy_val_op,\n",
        "        'train_loss': loss_train,\n",
        "        'val_loss': loss_val,\n",
        "        'train_update_loss': loss_train_op,\n",
        "        'val_update_loss': loss_val_op\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_xUOx5pRicd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_metrics = define_metrics(\n",
        "    'le_net/metrics/',\n",
        "    variables={\n",
        "        'target': le_net_target,\n",
        "        'predictions': le_net_predictions,\n",
        "        'loss': loss\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9_-qRSrkOBd",
        "colab_type": "code",
        "outputId": "1d4ce6c3-5d98-4b91-d79d-f7bb563cb743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "tf.local_variables()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'le_net/metrics/train/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss/count:0' shape=() dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD1gGzyOWEPY",
        "colab_type": "code",
        "outputId": "49fdf69d-dbf3-4fdb-a205-42ee4ac3b907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "y_train_labels = to_categorical(y_train)\n",
        "y_test_labels = to_categorical(y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPykTuBNYrHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset_metrics(scope):\n",
        "    stream_variables = [v for v in tf.local_variables() if scope in v.name]\n",
        "    sess.run(tf.variables_initializer(stream_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYD8nu_KzeLZ",
        "colab_type": "code",
        "outputId": "1bedf70a-ec8e-4595-f66a-75f538cd46de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check that data is ready\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "sess.run([loss, le_net_metrics['train_acc']], feed_dict={\n",
        "    digits_placeholder: X_train[:10],\n",
        "    labels_placeholder: y_train_labels[:10]\n",
        "})"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32.925728, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEN0LwAYyIAC",
        "colab_type": "code",
        "outputId": "422ff0f1-b9e5-4297-c0fb-69e17f13be82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "le_net_trainable_variables"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'le_net/conv1/conv/weights:0' shape=(5, 5, 3, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/conv1/conv/bias:0' shape=(6,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/conv2/conv/weights:0' shape=(5, 5, 6, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/conv2/conv/bias:0' shape=(16,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc1/weights:0' shape=(400, 120) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc1/bias:0' shape=(120,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc2/weights:0' shape=(120, 84) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc2/bias:0' shape=(84,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc3/weights:0' shape=(84, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc3/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ4jtls_UNpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_batches(X, y, batch_size, shuffle=True):\n",
        "    assert len(X) == len(y)\n",
        "    \n",
        "    indices = np.arange(len(X))\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    \n",
        "    for index in range(0, len(X), batch_size):\n",
        "        yield X[index:index + batch_size], y[index:index + batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9L01pAmzEUn",
        "colab_type": "code",
        "outputId": "cef56761-6926-4ae9-8c54-0869acf70ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch_num in range(50):\n",
        "    reset_metrics('le_net/metrics/train')\n",
        "    reset_metrics('le_net/metrics/val')\n",
        "    for X_batch, y_batch in iterate_batches(X_train, y_train_labels, 500):\n",
        "        _, _, _ = sess.run([\n",
        "            optimizer,\n",
        "            le_net_metrics['train_update_loss'], le_net_metrics['train_update_acc']\n",
        "        ], feed_dict={\n",
        "            digits_placeholder: X_batch,\n",
        "            labels_placeholder: y_batch\n",
        "        })\n",
        "        # print(loss_value, accuracy)\n",
        "    \n",
        "    print(f'Epoch {epoch_num + 1} train [acc, loss]:', sess.run([\n",
        "        le_net_metrics['train_acc'],\n",
        "        le_net_metrics['train_loss']\n",
        "    ]))\n",
        "    \n",
        "    for X_batch, y_batch in iterate_batches(X_test, y_test_labels, 500, shuffle=False):\n",
        "        _, _ = sess.run([\n",
        "            le_net_metrics['val_update_loss'],\n",
        "            le_net_metrics['val_update_acc']\n",
        "        ], feed_dict = {\n",
        "            digits_placeholder: X_batch,\n",
        "            labels_placeholder: y_batch\n",
        "        })\n",
        "    print(\n",
        "        f'Epoch {epoch_num + 1} val [acc, loss]:',\n",
        "        sess.run([\n",
        "            le_net_metrics['val_acc'],\n",
        "            le_net_metrics['val_loss']\n",
        "        ])\n",
        "    )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train [acc, loss]: [0.14222, 1.957949]\n",
            "Epoch 1 val [acc, loss]: [0.166, 0.43585435]\n",
            "Epoch 2 train [acc, loss]: [0.18926, 0.39143124]\n",
            "Epoch 2 val [acc, loss]: [0.1932, 0.35415822]\n",
            "Epoch 3 train [acc, loss]: [0.2346, 0.32454842]\n",
            "Epoch 3 val [acc, loss]: [0.2621, 0.30565962]\n",
            "Epoch 4 train [acc, loss]: [0.27802, 0.2972584]\n",
            "Epoch 4 val [acc, loss]: [0.2879, 0.29335552]\n",
            "Epoch 5 train [acc, loss]: [0.30456, 0.28565913]\n",
            "Epoch 5 val [acc, loss]: [0.3146, 0.28203708]\n",
            "Epoch 6 train [acc, loss]: [0.32786, 0.2790289]\n",
            "Epoch 6 val [acc, loss]: [0.3349, 0.27817523]\n",
            "Epoch 7 train [acc, loss]: [0.34214, 0.2748662]\n",
            "Epoch 7 val [acc, loss]: [0.3436, 0.27464357]\n",
            "Epoch 8 train [acc, loss]: [0.355, 0.27109167]\n",
            "Epoch 8 val [acc, loss]: [0.3559, 0.2714793]\n",
            "Epoch 9 train [acc, loss]: [0.36774, 0.2676653]\n",
            "Epoch 9 val [acc, loss]: [0.3641, 0.26994246]\n",
            "Epoch 10 train [acc, loss]: [0.37606, 0.2645841]\n",
            "Epoch 10 val [acc, loss]: [0.3761, 0.2671972]\n",
            "Epoch 11 train [acc, loss]: [0.3839, 0.26192906]\n",
            "Epoch 11 val [acc, loss]: [0.3795, 0.26493528]\n",
            "Epoch 12 train [acc, loss]: [0.39338, 0.25906008]\n",
            "Epoch 12 val [acc, loss]: [0.3899, 0.2613672]\n",
            "Epoch 13 train [acc, loss]: [0.39994, 0.25688508]\n",
            "Epoch 13 val [acc, loss]: [0.3955, 0.25943318]\n",
            "Epoch 14 train [acc, loss]: [0.40676, 0.2548536]\n",
            "Epoch 14 val [acc, loss]: [0.402, 0.2577287]\n",
            "Epoch 15 train [acc, loss]: [0.4111, 0.25339916]\n",
            "Epoch 15 val [acc, loss]: [0.4078, 0.25617296]\n",
            "Epoch 16 train [acc, loss]: [0.41604, 0.25192013]\n",
            "Epoch 16 val [acc, loss]: [0.4102, 0.25510123]\n",
            "Epoch 17 train [acc, loss]: [0.41978, 0.2505782]\n",
            "Epoch 17 val [acc, loss]: [0.4155, 0.2537427]\n",
            "Epoch 18 train [acc, loss]: [0.42372, 0.24912699]\n",
            "Epoch 18 val [acc, loss]: [0.4175, 0.2518446]\n",
            "Epoch 19 train [acc, loss]: [0.42838, 0.24774556]\n",
            "Epoch 19 val [acc, loss]: [0.4233, 0.25058508]\n",
            "Epoch 20 train [acc, loss]: [0.43318, 0.2465568]\n",
            "Epoch 20 val [acc, loss]: [0.4246, 0.24958737]\n",
            "Epoch 21 train [acc, loss]: [0.43652, 0.24548627]\n",
            "Epoch 21 val [acc, loss]: [0.425, 0.24879971]\n",
            "Epoch 22 train [acc, loss]: [0.44088, 0.24451101]\n",
            "Epoch 22 val [acc, loss]: [0.4295, 0.24730985]\n",
            "Epoch 23 train [acc, loss]: [0.44366, 0.24346201]\n",
            "Epoch 23 val [acc, loss]: [0.4337, 0.24616027]\n",
            "Epoch 24 train [acc, loss]: [0.44702, 0.24232005]\n",
            "Epoch 24 val [acc, loss]: [0.4342, 0.24538107]\n",
            "Epoch 25 train [acc, loss]: [0.45106, 0.2413257]\n",
            "Epoch 25 val [acc, loss]: [0.4368, 0.24474701]\n",
            "Epoch 26 train [acc, loss]: [0.45394, 0.24041753]\n",
            "Epoch 26 val [acc, loss]: [0.4397, 0.24359486]\n",
            "Epoch 27 train [acc, loss]: [0.45734, 0.2392599]\n",
            "Epoch 27 val [acc, loss]: [0.443, 0.2429996]\n",
            "Epoch 28 train [acc, loss]: [0.45912, 0.2384169]\n",
            "Epoch 28 val [acc, loss]: [0.4452, 0.2423323]\n",
            "Epoch 29 train [acc, loss]: [0.4635, 0.23762996]\n",
            "Epoch 29 val [acc, loss]: [0.4483, 0.24200904]\n",
            "Epoch 30 train [acc, loss]: [0.4668, 0.23683323]\n",
            "Epoch 30 val [acc, loss]: [0.4512, 0.2413948]\n",
            "Epoch 31 train [acc, loss]: [0.46914, 0.23599945]\n",
            "Epoch 31 val [acc, loss]: [0.4477, 0.241648]\n",
            "Epoch 32 train [acc, loss]: [0.47198, 0.23539843]\n",
            "Epoch 32 val [acc, loss]: [0.4497, 0.24075314]\n",
            "Epoch 33 train [acc, loss]: [0.47474, 0.23472235]\n",
            "Epoch 33 val [acc, loss]: [0.4496, 0.2408382]\n",
            "Epoch 34 train [acc, loss]: [0.4766, 0.23406269]\n",
            "Epoch 34 val [acc, loss]: [0.451, 0.24080949]\n",
            "Epoch 35 train [acc, loss]: [0.47932, 0.23357588]\n",
            "Epoch 35 val [acc, loss]: [0.4543, 0.24060488]\n",
            "Epoch 36 train [acc, loss]: [0.48196, 0.23279923]\n",
            "Epoch 36 val [acc, loss]: [0.4562, 0.2402596]\n",
            "Epoch 37 train [acc, loss]: [0.48412, 0.23192644]\n",
            "Epoch 37 val [acc, loss]: [0.4581, 0.23909195]\n",
            "Epoch 38 train [acc, loss]: [0.48688, 0.23115496]\n",
            "Epoch 38 val [acc, loss]: [0.4616, 0.23896149]\n",
            "Epoch 39 train [acc, loss]: [0.48918, 0.23025385]\n",
            "Epoch 39 val [acc, loss]: [0.4637, 0.23812032]\n",
            "Epoch 40 train [acc, loss]: [0.49462, 0.22906469]\n",
            "Epoch 40 val [acc, loss]: [0.4646, 0.2380908]\n",
            "Epoch 41 train [acc, loss]: [0.49812, 0.22822027]\n",
            "Epoch 41 val [acc, loss]: [0.4646, 0.23822561]\n",
            "Epoch 42 train [acc, loss]: [0.50096, 0.22748323]\n",
            "Epoch 42 val [acc, loss]: [0.4694, 0.23680225]\n",
            "Epoch 43 train [acc, loss]: [0.5029, 0.22671504]\n",
            "Epoch 43 val [acc, loss]: [0.4733, 0.23570564]\n",
            "Epoch 44 train [acc, loss]: [0.5059, 0.2258597]\n",
            "Epoch 44 val [acc, loss]: [0.4822, 0.23391858]\n",
            "Epoch 45 train [acc, loss]: [0.50886, 0.22487906]\n",
            "Epoch 45 val [acc, loss]: [0.4861, 0.23265214]\n",
            "Epoch 46 train [acc, loss]: [0.51076, 0.22411726]\n",
            "Epoch 46 val [acc, loss]: [0.4892, 0.23275574]\n",
            "Epoch 47 train [acc, loss]: [0.51394, 0.22334404]\n",
            "Epoch 47 val [acc, loss]: [0.4882, 0.23301725]\n",
            "Epoch 48 train [acc, loss]: [0.5164, 0.22258765]\n",
            "Epoch 48 val [acc, loss]: [0.4902, 0.23247488]\n",
            "Epoch 49 train [acc, loss]: [0.51758, 0.2220968]\n",
            "Epoch 49 val [acc, loss]: [0.4911, 0.23210505]\n",
            "Epoch 50 train [acc, loss]: [0.52088, 0.22139761]\n",
            "Epoch 50 val [acc, loss]: [0.4964, 0.23051384]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39z0nTz3piAC",
        "colab_type": "text"
      },
      "source": [
        "### Batch Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9jsK2O8pl7P",
        "colab_type": "text"
      },
      "source": [
        "Идея была высказана в 2014 году. Говорится,  что из-за смещенности градиентов нарушаются общие правила нормальности, применимые после входного слоя. Поэтому предлагается производить смещение в новый масштаб.\n",
        "\n",
        "Иными словами,\n",
        "\n",
        "$$\n",
        "    out = \\gamma \\cdot \\frac{x - \\mathrm{E}x}{\\sqrt{\\mathrm{D}x + \\varepsilon}} + \\beta,\n",
        "$$\n",
        "\n",
        "где $\\gamma$ и $\\beta$ являются обучаемыми параметрами. \n",
        "\n",
        "\n",
        "**Вопрос** Как вычислять значение $\\mathrm{E}x$, $\\mathrm{D}x$?\n",
        "\n",
        "**Ответ** Во время обучения: вычислять по batch-у, во время валидации - вычислять скользящее среднее по $\\mathrm{E}$ и $\\mathrm{D}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH3EfSGgVYNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(input_tensor, is_training, momentum=0.99, name='batch_norm'):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        shapes = input_tensor.get_shape().as_list()\n",
        "        \n",
        "        gamma = tf.get_variable('gamma', shape=shapes[1:], initializer=tf.ones_initializer())\n",
        "        beta = tf.get_variable('beta', shape=shapes[1:], initializer=tf.zeros_initializer())\n",
        "        \n",
        "        moving_mean = tf.get_variable('moving_mean', shape=shapes[1:], initializer=tf.zeros_initializer())\n",
        "        moving_var = tf.get_variable('moving_var', shape=shapes[1:], initializer=tf.ones_initializer())\n",
        "        \n",
        "        \n",
        "        updates = []\n",
        "        \n",
        "        def training_fn():\n",
        "            current_mean, current_var = tf.nn.moments(input_tensor, axes=0)\n",
        "            x_norm = (input_tensor - current_mean) / tf.sqrt(current_var + 1e-3)\n",
        "            updates.append(\n",
        "                tf.assign(moving_mean, moving_mean * momentum + current_mean * (1 - momentum))\n",
        "            )\n",
        "            updates.append(\n",
        "                tf.assign(moving_var, moving_var * momentum + current_var * (1 - momentum))\n",
        "            )\n",
        "            \n",
        "            return x_norm, updates\n",
        "        \n",
        "        def test_fn():\n",
        "            x_norm = (input_tensor - moving_mean) / tf.sqrt(moving_var + 1e-3)\n",
        "            return x_norm, updates\n",
        "        \n",
        "        \n",
        "        x_norm, updates = tf.cond(\n",
        "            is_training,\n",
        "            true_fn=training_fn,\n",
        "            false_fn=test_fn\n",
        "        )\n",
        "        \n",
        "        return gamma * x_norm + beta, updates\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEJ7vfQLT1J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block_with_bn(\n",
        "    x,\n",
        "    output_channels,\n",
        "    is_training,\n",
        "    name,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding='SAME'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        conv_out = conv_layer(\n",
        "            x, output_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=padding,\n",
        "            strides=strides\n",
        "        )\n",
        "        bn_out, updates = batch_norm(conv_out, is_training)\n",
        "        activation = tf.nn.relu(conv_out, name='relu')\n",
        "    return activation, updates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVD9hTEkZYxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def le_net_with_bn(input_tensor, is_training):\n",
        "    with tf.variable_scope('le_net_with_bn', reuse=tf.AUTO_REUSE):\n",
        "        conv1_out, updates_conv1 = conv_block_with_bn(\n",
        "            input_tensor, 6,\n",
        "            is_training=is_training,\n",
        "            name='conv1',\n",
        "            kernel_size=(5, 5),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        pool1_out = max_pool(conv1_out, name='pool1')\n",
        "        conv2_out, updates_conv2 = conv_block_with_bn(\n",
        "            pool1_out, 16,\n",
        "            is_training=is_training,\n",
        "            name='conv2',\n",
        "            kernel_size=(5, 5),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        \n",
        "        pool2_out = max_pool(conv2_out, name='pool2')\n",
        "        \n",
        "        flatten_out = flatten(pool2_out)\n",
        "        \n",
        "        fc1_out = dense(flatten_out, 120, name='fc1')\n",
        "        fc2_out = dense(fc1_out, 84, name='fc2')\n",
        "        \n",
        "        output = dense(fc2_out, 10, name='fc3')\n",
        "    return output, updates_conv1 + updates_conv2\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqA8xj-dZ7xl",
        "colab_type": "code",
        "outputId": "745723f3-e01a-4df2-f148-609a3ef35c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "digits_placeholder = tf.placeholder(tf.float32, [None, 32, 32, 3], name='digits_bn')\n",
        "le_net_is_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "logits, le_net_bn_updates = le_net_with_bn(digits_placeholder, is_training=le_net_is_training)\n",
        "labels_placeholder = tf.placeholder(tf.float32, [None, 10], name='le_net_labels_bn')\n",
        "\n",
        "\n",
        "loss = tf.reduce_mean(\n",
        "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=labels_placeholder,\n",
        "        logits=logits\n",
        "    ),\n",
        "    name='le_net_loss_bn'\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 6\n",
            "6 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tFRKmpyaoKU",
        "colab_type": "code",
        "outputId": "3cbaffc5-ac97-4423-9dbc-074fcf533a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "le_net_bn_updates"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'le_net_with_bn/conv1/batch_norm/cond/Merge_1:0' shape=(28, 28, 6) dtype=float32_ref>,\n",
              " <tf.Tensor 'le_net_with_bn/conv1/batch_norm/cond/Merge_2:0' shape=(28, 28, 6) dtype=float32_ref>,\n",
              " <tf.Tensor 'le_net_with_bn/conv2/batch_norm/cond/Merge_1:0' shape=(10, 10, 16) dtype=float32_ref>,\n",
              " <tf.Tensor 'le_net_with_bn/conv2/batch_norm/cond/Merge_2:0' shape=(10, 10, 16) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcnJYCp-azMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_predictions = tf.argmax(logits, axis=1)\n",
        "le_net_target = tf.argmax(labels_placeholder, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRiDz0g5a4WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='le_net_with_bn')\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss, var_list=le_net_trainable_variables)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjiNRfpIUA3W",
        "colab_type": "code",
        "outputId": "f189ade1-fb96-4dfb-879e-5f6ac461442d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "le_net_trainable_variables"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'le_net_with_bn/conv1/conv/weights:0' shape=(5, 5, 3, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv1/conv/bias:0' shape=(6,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv1/batch_norm/gamma:0' shape=(28, 28, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv1/batch_norm/beta:0' shape=(28, 28, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv1/batch_norm/moving_mean:0' shape=(28, 28, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv1/batch_norm/moving_var:0' shape=(28, 28, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv2/conv/weights:0' shape=(5, 5, 6, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv2/conv/bias:0' shape=(16,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv2/batch_norm/gamma:0' shape=(10, 10, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv2/batch_norm/beta:0' shape=(10, 10, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv2/batch_norm/moving_mean:0' shape=(10, 10, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/conv2/batch_norm/moving_var:0' shape=(10, 10, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/fc1/weights:0' shape=(400, 120) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/fc1/bias:0' shape=(120,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/fc2/weights:0' shape=(120, 84) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/fc2/bias:0' shape=(84,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/fc3/weights:0' shape=(84, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/fc3/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLP-mUPoTbNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_bn_metrics = define_metrics(\n",
        "    'le_net_with_bn/metrics/',\n",
        "    variables={\n",
        "        'target': le_net_target,\n",
        "        'predictions': le_net_predictions,\n",
        "        'loss': loss\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L2IRTaeCIst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "abc49797-a917-4d05-c06f-062a7d1279ae"
      },
      "source": [
        "le_net_bn_metrics"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_acc': <tf.Tensor 'le_net_with_bn/metrics/train/accuracy/value:0' shape=() dtype=float32>,\n",
              " 'train_loss': <tf.Tensor 'le_net_with_bn/metrics/train/loss/value:0' shape=() dtype=float32>,\n",
              " 'train_update_acc': <tf.Tensor 'le_net_with_bn/metrics/train/accuracy/update_op:0' shape=() dtype=float32>,\n",
              " 'train_update_loss': <tf.Tensor 'le_net_with_bn/metrics/train/loss/update_op:0' shape=() dtype=float32>,\n",
              " 'val_acc': <tf.Tensor 'le_net_with_bn/metrics/val/accuracy/value:0' shape=() dtype=float32>,\n",
              " 'val_loss': <tf.Tensor 'le_net_with_bn/metrics/val/loss/value:0' shape=() dtype=float32>,\n",
              " 'val_update_acc': <tf.Tensor 'le_net_with_bn/metrics/val/accuracy/update_op:0' shape=() dtype=float32>,\n",
              " 'val_update_loss': <tf.Tensor 'le_net_with_bn/metrics/val/loss/update_op:0' shape=() dtype=float32>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz5P4qjobi3C",
        "colab_type": "code",
        "outputId": "ba783b9b-983a-44dd-ab91-058639112496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check that data is ready\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "sess.run([loss, le_net_bn_metrics['train_acc']], feed_dict={\n",
        "    digits_placeholder: X_train[:10],\n",
        "    labels_placeholder: y_train_labels[:10]\n",
        "})"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22.364988, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0V-PSDPbtcE",
        "colab_type": "code",
        "outputId": "095979c3-6f36-49b8-d011-f760e27498c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess.run([le_net_bn_updates], feed_dict={\n",
        "    digits_placeholder: X_train[:10],\n",
        "    labels_placeholder: y_train_labels[:10],\n",
        "    le_net_is_training: True\n",
        "})"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[array([[[-0.16407284,  1.0582566 ,  0.49639064, -0.57666016,\n",
              "           -1.404595  ,  0.15376146],\n",
              "          [-0.14000908,  1.0887748 ,  0.42709774, -0.48115355,\n",
              "           -1.431537  ,  0.19883224],\n",
              "          [-0.1307742 ,  1.0461471 ,  0.35974836, -0.502143  ,\n",
              "           -1.5157933 ,  0.25849476],\n",
              "          ...,\n",
              "          [-0.10115059,  1.1696378 ,  0.4968646 , -0.47575235,\n",
              "           -1.6587679 ,  0.22849438],\n",
              "          [-0.13130185,  1.1651713 ,  0.4736112 , -0.5471004 ,\n",
              "           -1.6478977 ,  0.21327946],\n",
              "          [-0.11243341,  1.189932  ,  0.44842914, -0.5278385 ,\n",
              "           -1.6744676 ,  0.28889567]],\n",
              "  \n",
              "         [[-0.15556505,  1.0896169 ,  0.5028192 , -0.50595677,\n",
              "           -1.4080948 ,  0.11055938],\n",
              "          [-0.19068243,  1.1225442 ,  0.44356486, -0.49531278,\n",
              "           -1.4199865 ,  0.13103385],\n",
              "          [-0.1498605 ,  1.0961143 ,  0.41902775, -0.5402847 ,\n",
              "           -1.4916962 ,  0.22528479],\n",
              "          ...,\n",
              "          [-0.08607972,  1.1639233 ,  0.40153524, -0.45138568,\n",
              "           -1.6760131 ,  0.29358616],\n",
              "          [-0.11432473,  1.1026975 ,  0.38270706, -0.5131733 ,\n",
              "           -1.66117   ,  0.3198012 ],\n",
              "          [-0.13460077,  1.1402793 ,  0.44724727, -0.5116651 ,\n",
              "           -1.619896  ,  0.3528902 ]],\n",
              "  \n",
              "         [[-0.11668339,  1.1305753 ,  0.45623824, -0.44277403,\n",
              "           -1.4768717 ,  0.10871799],\n",
              "          [-0.12589265,  1.1098447 ,  0.43464598, -0.45935798,\n",
              "           -1.4954423 ,  0.14908391],\n",
              "          [-0.14314829,  1.0770186 ,  0.42904884, -0.49046788,\n",
              "           -1.5091729 ,  0.23553115],\n",
              "          ...,\n",
              "          [-0.09229144,  1.1003318 ,  0.4723729 , -0.43799973,\n",
              "           -1.6240346 ,  0.31340307],\n",
              "          [-0.1360185 ,  1.0267879 ,  0.45179713, -0.45768005,\n",
              "           -1.5741174 ,  0.273972  ],\n",
              "          [-0.16107745,  1.0611032 ,  0.54647034, -0.48738134,\n",
              "           -1.4731127 ,  0.26748523]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[ 0.02283897,  0.9606747 ,  0.5777229 , -0.31010476,\n",
              "           -1.5250643 ,  0.2747623 ],\n",
              "          [-0.00859698,  0.887518  ,  0.559082  , -0.26032475,\n",
              "           -1.3961606 ,  0.25589705],\n",
              "          [-0.0219161 ,  0.92000026,  0.5744462 , -0.22029579,\n",
              "           -1.2898592 ,  0.2017823 ],\n",
              "          ...,\n",
              "          [-0.03723545,  0.6160431 ,  0.28228566, -0.02364872,\n",
              "           -0.95216304,  0.01795781],\n",
              "          [-0.05245565,  0.6594904 ,  0.1795055 , -0.12855978,\n",
              "           -0.8931597 ,  0.05869363],\n",
              "          [-0.01838417,  0.7592894 ,  0.21762936, -0.14589792,\n",
              "           -0.98348206,  0.12194773]],\n",
              "  \n",
              "         [[-0.00669234,  0.9936693 ,  0.654267  , -0.26400864,\n",
              "           -1.4921407 ,  0.13340196],\n",
              "          [-0.02307177,  0.94556797,  0.62107545, -0.21561615,\n",
              "           -1.4190365 ,  0.10609224],\n",
              "          [-0.01703452,  0.942671  ,  0.59963816, -0.19302936,\n",
              "           -1.3653697 ,  0.06324645],\n",
              "          ...,\n",
              "          [ 0.00998257,  0.63257873,  0.23240188, -0.04891555,\n",
              "           -1.0017881 ,  0.08198804],\n",
              "          [-0.02204465,  0.6478395 ,  0.189331  , -0.10511637,\n",
              "           -0.9586354 ,  0.13591327],\n",
              "          [ 0.01973404,  0.7106591 ,  0.30674765, -0.15682422,\n",
              "           -1.0426711 ,  0.15595865]],\n",
              "  \n",
              "         [[ 0.01974826,  0.98478335,  0.55878866, -0.26495934,\n",
              "           -1.5710121 ,  0.10372049],\n",
              "          [ 0.04600188,  0.958591  ,  0.519965  , -0.22221701,\n",
              "           -1.5488746 ,  0.06009297],\n",
              "          [ 0.07669216,  0.9576325 ,  0.48677078, -0.17571574,\n",
              "           -1.5403345 ,  0.07891332],\n",
              "          ...,\n",
              "          [-0.00703928,  0.68995416,  0.29169062, -0.1088766 ,\n",
              "           -1.0202624 ,  0.07551763],\n",
              "          [-0.02172084,  0.70657605,  0.30087176, -0.13085477,\n",
              "           -0.9711953 ,  0.11381868],\n",
              "          [ 0.02443038,  0.7293193 ,  0.39358416, -0.12443394,\n",
              "           -1.092395  ,  0.10526996]]], dtype=float32),\n",
              "  array([[[ 3.2150626, 35.539795 ,  8.446104 , 23.96156  , 83.03443  ,\n",
              "           11.632521 ],\n",
              "          [ 3.959485 , 32.5645   ,  7.0202217, 26.267014 , 68.89056  ,\n",
              "            9.714583 ],\n",
              "          [ 5.2066317, 31.797712 ,  8.798668 , 25.078363 , 54.464985 ,\n",
              "            9.937326 ],\n",
              "          ...,\n",
              "          [ 5.654808 , 22.683695 , 13.036566 , 28.998022 , 37.177265 ,\n",
              "           14.534917 ],\n",
              "          [ 4.3956976, 23.925278 , 11.981201 , 21.3142   , 36.236465 ,\n",
              "           13.960918 ],\n",
              "          [ 5.1896086, 19.749641 , 14.412184 , 22.717976 , 33.503716 ,\n",
              "            9.566554 ]],\n",
              "  \n",
              "         [[ 8.97548  , 33.49442  ,  8.599932 , 30.89669  , 66.10614  ,\n",
              "           11.902189 ],\n",
              "          [ 8.373417 , 35.534916 , 10.174988 , 28.161476 , 51.32401  ,\n",
              "            9.129574 ],\n",
              "          [ 9.138977 , 35.247486 , 12.37094  , 26.652819 , 45.749645 ,\n",
              "            7.2111025],\n",
              "          ...,\n",
              "          [ 6.652748 , 22.57055  , 13.656413 , 25.5478   , 41.848705 ,\n",
              "            7.783182 ],\n",
              "          [ 6.341977 , 28.522953 , 14.51936  , 21.11487  , 42.61044  ,\n",
              "            7.8285027],\n",
              "          [ 5.335313 , 25.229015 , 12.723743 , 21.76549  , 42.914745 ,\n",
              "            7.1159983]],\n",
              "  \n",
              "         [[11.153731 , 25.34546  ,  9.981151 , 27.228168 , 46.978256 ,\n",
              "            5.284333 ],\n",
              "          [ 9.082397 , 29.913998 , 14.820018 , 25.991138 , 42.96036  ,\n",
              "            4.7610445],\n",
              "          [11.761537 , 31.046846 , 20.020151 , 25.988726 , 46.730583 ,\n",
              "            4.605115 ],\n",
              "          ...,\n",
              "          [ 8.029332 , 29.90478  , 10.993184 , 27.137016 , 38.15605  ,\n",
              "            2.7255316],\n",
              "          [ 7.2302103, 35.88482  , 13.296496 , 25.757635 , 43.233192 ,\n",
              "            7.667877 ],\n",
              "          [ 6.021736 , 31.449242 , 11.062395 , 21.825718 , 53.42494  ,\n",
              "            6.4946766]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[ 8.092416 , 20.484495 , 12.301418 , 15.517366 , 29.68004  ,\n",
              "            8.697636 ],\n",
              "          [ 8.484285 , 19.442757 , 11.272227 , 17.157576 , 30.306984 ,\n",
              "           12.053896 ],\n",
              "          [ 9.584923 , 22.34247  , 11.806038 , 13.487235 , 35.085346 ,\n",
              "            8.187561 ],\n",
              "          ...,\n",
              "          [ 5.3650713, 11.771338 ,  6.213275 , 11.378307 , 28.26099  ,\n",
              "            6.0084476],\n",
              "          [ 8.316985 , 12.2024145, 28.042925 , 12.607843 , 25.407022 ,\n",
              "            5.032508 ],\n",
              "          [13.461679 , 14.778039 , 14.400212 , 13.214504 , 34.32268  ,\n",
              "           18.052906 ]],\n",
              "  \n",
              "         [[ 6.3039103, 16.204329 , 17.157433 , 13.726899 , 29.604687 ,\n",
              "            5.3313665],\n",
              "          [ 8.137348 , 15.189206 , 17.17866  , 13.852932 , 29.571589 ,\n",
              "            3.9462662],\n",
              "          [ 8.349095 , 15.139525 , 10.628453 , 11.463725 , 31.284569 ,\n",
              "            7.65279  ],\n",
              "          ...,\n",
              "          [ 7.0576477,  9.717823 , 11.797199 ,  8.531993 , 23.017614 ,\n",
              "            5.6745033],\n",
              "          [ 7.6875076, 11.201263 , 20.821468 , 11.588926 , 21.580406 ,\n",
              "           11.749805 ],\n",
              "          [ 9.849889 , 10.986027 ,  7.9743366, 13.482942 , 23.402027 ,\n",
              "           12.939904 ]],\n",
              "  \n",
              "         [[ 7.0906334, 15.550882 , 14.817571 , 15.591894 , 25.929514 ,\n",
              "            5.7417336],\n",
              "          [ 9.0842285, 12.613975 , 14.891191 , 18.07745  , 25.706667 ,\n",
              "            9.444061 ],\n",
              "          [ 6.7852955, 12.26247  ,  7.6608973, 13.287351 , 25.331615 ,\n",
              "           10.058857 ],\n",
              "          ...,\n",
              "          [ 6.4056215, 11.746479 ,  6.1120825,  7.4427576, 18.330742 ,\n",
              "            4.065695 ],\n",
              "          [ 7.3612757, 12.486612 ,  6.342787 ,  9.858598 , 22.181253 ,\n",
              "           10.148535 ],\n",
              "          [ 7.8863134, 12.291308 ,  9.255761 , 13.309877 , 21.800024 ,\n",
              "            3.618771 ]]], dtype=float32),\n",
              "  array([[[-0.05116975, -0.2818545 ,  0.10351156, ...,  0.07369826,\n",
              "           -0.26644266,  0.00072274],\n",
              "          [-0.03250754, -0.29371113,  0.12355299, ...,  0.0569409 ,\n",
              "           -0.26333678, -0.00184587],\n",
              "          [-0.02944118, -0.29255247,  0.13244043, ...,  0.09843625,\n",
              "           -0.27298605,  0.00137426],\n",
              "          ...,\n",
              "          [-0.09840117, -0.26626983,  0.17935763, ...,  0.12134852,\n",
              "           -0.3138386 , -0.00060434],\n",
              "          [-0.04630038, -0.21495229,  0.11434576, ...,  0.0924386 ,\n",
              "           -0.2966265 , -0.04221676],\n",
              "          [-0.09410989, -0.23606677,  0.145259  , ...,  0.07950991,\n",
              "           -0.267355  , -0.02410742]],\n",
              "  \n",
              "         [[-0.11003499, -0.21480761,  0.06173173, ...,  0.08022976,\n",
              "           -0.25077155, -0.02167515],\n",
              "          [-0.12948458, -0.2067253 ,  0.06589568, ...,  0.06182431,\n",
              "           -0.2361491 , -0.04330203],\n",
              "          [-0.08877547, -0.24467036,  0.08684596, ...,  0.05505582,\n",
              "           -0.26405647, -0.00911309],\n",
              "          ...,\n",
              "          [-0.12491275, -0.2482089 ,  0.15119272, ...,  0.10316408,\n",
              "           -0.2039961 ,  0.01040475],\n",
              "          [-0.053055  , -0.23047613,  0.08817799, ...,  0.03990984,\n",
              "           -0.28416857, -0.08277758],\n",
              "          [-0.0311138 , -0.26443797,  0.12274726, ...,  0.11393903,\n",
              "           -0.22843927, -0.01711623]],\n",
              "  \n",
              "         [[-0.09338742, -0.14465837,  0.04955785, ...,  0.1233649 ,\n",
              "           -0.2563196 , -0.09746838],\n",
              "          [-0.08360989, -0.17168702,  0.07496478, ...,  0.08553581,\n",
              "           -0.24993837, -0.08700391],\n",
              "          [-0.04242909, -0.19492458,  0.07462552, ...,  0.07467845,\n",
              "           -0.26386824, -0.01714326],\n",
              "          ...,\n",
              "          [-0.10750926, -0.2533717 ,  0.05801253, ...,  0.1098716 ,\n",
              "           -0.24179439, -0.02810163],\n",
              "          [-0.12077383, -0.1863641 ,  0.07365191, ...,  0.05374142,\n",
              "           -0.2188366 , -0.12559126],\n",
              "          [-0.09961414, -0.23517108,  0.01370382, ...,  0.03381221,\n",
              "           -0.21634111, -0.07987875]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[-0.09612867, -0.19770308,  0.14545885, ...,  0.09563635,\n",
              "           -0.21822712, -0.09441498],\n",
              "          [-0.06325538, -0.18522836,  0.12820096, ...,  0.09069429,\n",
              "           -0.22434486, -0.02748809],\n",
              "          [-0.11977268, -0.19883807,  0.2022778 , ...,  0.08408131,\n",
              "           -0.22579125,  0.03059917],\n",
              "          ...,\n",
              "          [-0.05696   , -0.1674781 ,  0.12844476, ...,  0.07371247,\n",
              "           -0.16472492, -0.12379744],\n",
              "          [-0.06217837, -0.17393184,  0.15046808, ...,  0.02836718,\n",
              "           -0.14973806, -0.11904455],\n",
              "          [-0.03167557, -0.200481  ,  0.17527126, ..., -0.00755212,\n",
              "           -0.17659542,  0.01553763]],\n",
              "  \n",
              "         [[-0.08395785, -0.19210258,  0.12767859, ...,  0.13748609,\n",
              "           -0.23249981, -0.02199654],\n",
              "          [-0.08103556, -0.23983397,  0.13420853, ...,  0.07286455,\n",
              "           -0.1555033 , -0.0124306 ],\n",
              "          [-0.13007197, -0.2810782 ,  0.134151  , ...,  0.05339603,\n",
              "           -0.14580813, -0.03866432],\n",
              "          ...,\n",
              "          [-0.14523783, -0.2004464 ,  0.05954978, ...,  0.04431387,\n",
              "           -0.176835  , -0.0707321 ],\n",
              "          [-0.11277456, -0.21616329,  0.0780796 , ...,  0.04209708,\n",
              "           -0.09542237, -0.00345883],\n",
              "          [-0.06912712, -0.22235054,  0.0829745 , ...,  0.0474808 ,\n",
              "           -0.12415434, -0.04266089]],\n",
              "  \n",
              "         [[-0.13046402, -0.22169611,  0.04354947, ...,  0.06300093,\n",
              "           -0.2102327 , -0.00923638],\n",
              "          [-0.10195314, -0.23173502,  0.03663137, ...,  0.0117137 ,\n",
              "           -0.17332481,  0.01050096],\n",
              "          [-0.14001714, -0.30155033,  0.02411678, ...,  0.01769602,\n",
              "           -0.1371758 , -0.00837147],\n",
              "          ...,\n",
              "          [-0.15880777, -0.26003718, -0.01763984, ...,  0.12195618,\n",
              "           -0.11658594, -0.03866509],\n",
              "          [-0.08286892, -0.19545078, -0.01049073, ...,  0.10890203,\n",
              "           -0.16108161, -0.01465688],\n",
              "          [-0.06920588, -0.18818142,  0.02374326, ...,  0.04951349,\n",
              "           -0.2022015 , -0.07393136]]], dtype=float32),\n",
              "  array([[[2.2531607, 3.125014 , 2.7242534, ..., 2.4153419, 3.5265594,\n",
              "           2.3260293],\n",
              "          [2.6435513, 2.186596 , 3.2342072, ..., 2.9615626, 3.5267496,\n",
              "           2.3881106],\n",
              "          [3.1122885, 1.7388976, 3.1589413, ..., 2.7312324, 4.9520006,\n",
              "           2.1330965],\n",
              "          ...,\n",
              "          [3.7840567, 5.352236 , 4.9276056, ..., 3.6630926, 3.9453697,\n",
              "           6.856224 ],\n",
              "          [3.7519412, 5.4695606, 2.7947612, ..., 3.48118  , 2.6808953,\n",
              "           3.2613187],\n",
              "          [2.68873  , 6.238756 , 3.1447806, ..., 4.0087395, 3.2266781,\n",
              "           2.9878807]],\n",
              "  \n",
              "         [[3.7653427, 3.949446 , 3.8325725, ..., 2.14554  , 2.2529154,\n",
              "           4.5396914],\n",
              "          [3.6744635, 3.6000345, 2.7385259, ..., 2.9475448, 3.1415055,\n",
              "           2.743465 ],\n",
              "          [3.033602 , 3.6067815, 2.6905565, ..., 1.6764014, 5.9255257,\n",
              "           2.103557 ],\n",
              "          ...,\n",
              "          [3.3757138, 3.3205373, 9.445572 , ..., 2.1514697, 4.5941997,\n",
              "           6.247118 ],\n",
              "          [4.9610186, 3.5879695, 7.6601973, ..., 2.4875457, 5.479849 ,\n",
              "           5.3165474],\n",
              "          [2.5104742, 3.1653304, 4.0057015, ..., 2.1567044, 2.7608786,\n",
              "           2.5495224]],\n",
              "  \n",
              "         [[6.1985226, 4.0191946, 3.2904842, ..., 2.277122 , 3.195588 ,\n",
              "           6.091298 ],\n",
              "          [4.967991 , 2.6132548, 3.781507 , ..., 1.9886292, 2.1909995,\n",
              "           2.1277854],\n",
              "          [3.514216 , 2.5618892, 4.598592 , ..., 1.8421495, 3.2989638,\n",
              "           4.794479 ],\n",
              "          ...,\n",
              "          [2.6920009, 3.7049017, 5.0740547, ..., 8.5784   , 3.6953888,\n",
              "           4.666635 ],\n",
              "          [2.4110663, 2.2008333, 3.696513 , ..., 5.2340107, 6.5532007,\n",
              "           2.7662125],\n",
              "          [3.6753128, 3.3760512, 4.5628796, ..., 3.5829084, 7.1354218,\n",
              "           2.9270072]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[1.3436761, 4.3025737, 3.894501 , ..., 3.368848 , 2.3103542,\n",
              "           4.745918 ],\n",
              "          [1.6488392, 2.9610248, 4.4206095, ..., 2.7936707, 3.8278127,\n",
              "           5.8304634],\n",
              "          [3.540214 , 1.8190186, 6.942584 , ..., 3.0101209, 4.554837 ,\n",
              "           4.9163094],\n",
              "          ...,\n",
              "          [2.4965577, 3.0231729, 7.191639 , ..., 3.714103 , 2.5429988,\n",
              "           2.2715514],\n",
              "          [1.8972609, 3.7475786, 5.81419  , ..., 6.877039 , 2.0440502,\n",
              "           5.9671707],\n",
              "          [1.9285573, 5.676876 , 3.1401558, ..., 7.775531 , 3.7231677,\n",
              "           3.3308144]],\n",
              "  \n",
              "         [[2.4055612, 2.1408234, 6.8296127, ..., 3.699306 , 4.8837795,\n",
              "           5.8485107],\n",
              "          [1.8950043, 2.3249233, 7.380454 , ..., 3.668991 , 2.7438543,\n",
              "           6.6607523],\n",
              "          [3.254507 , 4.159098 , 9.341821 , ..., 3.8817575, 2.4194236,\n",
              "           4.6115646],\n",
              "          ...,\n",
              "          [3.8519263, 5.2148514, 7.3927937, ..., 5.384368 , 5.177986 ,\n",
              "           3.8130107],\n",
              "          [3.4224038, 4.434761 , 4.7792535, ..., 4.097332 , 3.5058532,\n",
              "           5.5556   ],\n",
              "          [3.819545 , 3.8522851, 4.215314 , ..., 2.2622662, 2.6731424,\n",
              "           4.739111 ]],\n",
              "  \n",
              "         [[2.387137 , 4.9649158, 3.7144606, ..., 3.4996045, 4.3542566,\n",
              "           8.659276 ],\n",
              "          [2.0143797, 3.1096528, 5.4124384, ..., 3.6117477, 3.589057 ,\n",
              "           2.8447676],\n",
              "          [3.2641997, 4.108962 , 7.424941 , ..., 3.0325773, 2.1728954,\n",
              "           6.4162693],\n",
              "          ...,\n",
              "          [2.9615157, 4.733181 , 5.175658 , ..., 3.1518946, 4.9984226,\n",
              "           3.1081383],\n",
              "          [2.6468246, 2.6612887, 3.3191624, ..., 3.8732572, 2.5002394,\n",
              "           5.9655094],\n",
              "          [2.5107653, 3.383353 , 4.114664 , ..., 5.0320425, 2.6593814,\n",
              "           4.2842007]]], dtype=float32)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc8Vw3F5cEYe",
        "colab_type": "code",
        "outputId": "f34ce2e0-8ec0-40e8-b176-9334a3980c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "tf.local_variables()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'le_net/metrics/train/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/train/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/train/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/train/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/train/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/val/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/val/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/val/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net_with_bn/metrics/val/loss/count:0' shape=() dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvtBwAdIUpXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDtKjniCcCPE",
        "colab_type": "code",
        "outputId": "0b93daa1-7836-4ff3-bbe2-20e03bc7bef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch_num in range(50):\n",
        "    reset_metrics('le_net_with_bn/metrics/train')\n",
        "    reset_metrics('le_net_with_bn/metrics/val')\n",
        "    for X_batch, y_batch in iterate_batches(X_train, y_train_labels, 500):\n",
        "        _, _, _, _ = sess.run([\n",
        "            optimizer,\n",
        "            le_net_bn_metrics['train_update_acc'],\n",
        "            le_net_bn_metrics['train_update_loss'],\n",
        "            le_net_bn_updates\n",
        "        ], feed_dict={\n",
        "            digits_placeholder: X_batch,\n",
        "            labels_placeholder: y_batch,\n",
        "            le_net_is_training: True\n",
        "        })\n",
        "        # print(loss_value, accuracy)\n",
        "    \n",
        "    print(f'Epoch {epoch_num + 1} train [acc, loss]:', sess.run([\n",
        "        le_net_bn_metrics['train_acc'],\n",
        "        le_net_bn_metrics['train_loss']\n",
        "    ]))\n",
        "    \n",
        "    for X_batch, y_batch in iterate_batches(X_test, y_test_labels, 500, shuffle=False):\n",
        "        _, _ = sess.run([\n",
        "            le_net_bn_metrics['val_update_acc'],\n",
        "            le_net_bn_metrics['val_update_loss']\n",
        "        ], feed_dict = {\n",
        "            digits_placeholder: X_batch,\n",
        "            labels_placeholder: y_batch,\n",
        "            le_net_is_training: False\n",
        "        })\n",
        "    print(\n",
        "        f'Epoch {epoch_num + 1} val [acc, loss]:',\n",
        "        sess.run([\n",
        "            le_net_bn_metrics['val_acc'], \n",
        "            le_net_bn_metrics['val_loss']\n",
        "        ])\n",
        "    )"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train [acc, loss]: [0.12042, 1.5332496]\n",
            "Epoch 1 val [acc, loss]: [0.1422, 0.3861373]\n",
            "Epoch 2 train [acc, loss]: [0.15902, 0.343173]\n",
            "Epoch 2 val [acc, loss]: [0.1616, 0.33117783]\n",
            "Epoch 3 train [acc, loss]: [0.17058, 0.32882544]\n",
            "Epoch 3 val [acc, loss]: [0.1645, 0.32951722]\n",
            "Epoch 4 train [acc, loss]: [0.17964, 0.32515132]\n",
            "Epoch 4 val [acc, loss]: [0.184, 0.32179418]\n",
            "Epoch 5 train [acc, loss]: [0.18896, 0.32161912]\n",
            "Epoch 5 val [acc, loss]: [0.1825, 0.32318428]\n",
            "Epoch 6 train [acc, loss]: [0.1944, 0.3194045]\n",
            "Epoch 6 val [acc, loss]: [0.1919, 0.3188106]\n",
            "Epoch 7 train [acc, loss]: [0.20412, 0.31675336]\n",
            "Epoch 7 val [acc, loss]: [0.2055, 0.31677675]\n",
            "Epoch 8 train [acc, loss]: [0.2202, 0.31325755]\n",
            "Epoch 8 val [acc, loss]: [0.2145, 0.317038]\n",
            "Epoch 9 train [acc, loss]: [0.25834, 0.30268973]\n",
            "Epoch 9 val [acc, loss]: [0.2886, 0.30004504]\n",
            "Epoch 10 train [acc, loss]: [0.28802, 0.2937021]\n",
            "Epoch 10 val [acc, loss]: [0.2981, 0.29480597]\n",
            "Epoch 11 train [acc, loss]: [0.3013, 0.28903592]\n",
            "Epoch 11 val [acc, loss]: [0.3067, 0.2927572]\n",
            "Epoch 12 train [acc, loss]: [0.31344, 0.28528258]\n",
            "Epoch 12 val [acc, loss]: [0.3127, 0.28967243]\n",
            "Epoch 13 train [acc, loss]: [0.32524, 0.28178334]\n",
            "Epoch 13 val [acc, loss]: [0.3228, 0.28623492]\n",
            "Epoch 14 train [acc, loss]: [0.33522, 0.27842358]\n",
            "Epoch 14 val [acc, loss]: [0.3333, 0.28414917]\n",
            "Epoch 15 train [acc, loss]: [0.34612, 0.27484202]\n",
            "Epoch 15 val [acc, loss]: [0.3437, 0.27775365]\n",
            "Epoch 16 train [acc, loss]: [0.35738, 0.27087396]\n",
            "Epoch 16 val [acc, loss]: [0.3547, 0.2741552]\n",
            "Epoch 17 train [acc, loss]: [0.36706, 0.26792985]\n",
            "Epoch 17 val [acc, loss]: [0.369, 0.27107692]\n",
            "Epoch 18 train [acc, loss]: [0.37318, 0.26607633]\n",
            "Epoch 18 val [acc, loss]: [0.3747, 0.26869708]\n",
            "Epoch 19 train [acc, loss]: [0.37752, 0.26461515]\n",
            "Epoch 19 val [acc, loss]: [0.3782, 0.26775452]\n",
            "Epoch 20 train [acc, loss]: [0.37978, 0.26355684]\n",
            "Epoch 20 val [acc, loss]: [0.3809, 0.26712]\n",
            "Epoch 21 train [acc, loss]: [0.38406, 0.2625324]\n",
            "Epoch 21 val [acc, loss]: [0.3839, 0.26716414]\n",
            "Epoch 22 train [acc, loss]: [0.3856, 0.2618438]\n",
            "Epoch 22 val [acc, loss]: [0.3849, 0.26587585]\n",
            "Epoch 23 train [acc, loss]: [0.39044, 0.26091498]\n",
            "Epoch 23 val [acc, loss]: [0.391, 0.26403618]\n",
            "Epoch 24 train [acc, loss]: [0.39336, 0.26016116]\n",
            "Epoch 24 val [acc, loss]: [0.3938, 0.26232982]\n",
            "Epoch 25 train [acc, loss]: [0.39764, 0.2591512]\n",
            "Epoch 25 val [acc, loss]: [0.3947, 0.26162615]\n",
            "Epoch 26 train [acc, loss]: [0.40026, 0.25822935]\n",
            "Epoch 26 val [acc, loss]: [0.3991, 0.26157862]\n",
            "Epoch 27 train [acc, loss]: [0.40416, 0.2574493]\n",
            "Epoch 27 val [acc, loss]: [0.399, 0.2602328]\n",
            "Epoch 28 train [acc, loss]: [0.41284, 0.25548387]\n",
            "Epoch 28 val [acc, loss]: [0.4058, 0.2585391]\n",
            "Epoch 29 train [acc, loss]: [0.41812, 0.25403425]\n",
            "Epoch 29 val [acc, loss]: [0.4196, 0.2563627]\n",
            "Epoch 30 train [acc, loss]: [0.42486, 0.252266]\n",
            "Epoch 30 val [acc, loss]: [0.4279, 0.2544173]\n",
            "Epoch 31 train [acc, loss]: [0.43084, 0.25060096]\n",
            "Epoch 31 val [acc, loss]: [0.4336, 0.2523672]\n",
            "Epoch 32 train [acc, loss]: [0.43346, 0.24931194]\n",
            "Epoch 32 val [acc, loss]: [0.4365, 0.25084537]\n",
            "Epoch 33 train [acc, loss]: [0.43816, 0.24775171]\n",
            "Epoch 33 val [acc, loss]: [0.4428, 0.250047]\n",
            "Epoch 34 train [acc, loss]: [0.44302, 0.24647182]\n",
            "Epoch 34 val [acc, loss]: [0.4442, 0.25082108]\n",
            "Epoch 35 train [acc, loss]: [0.44602, 0.24550667]\n",
            "Epoch 35 val [acc, loss]: [0.4454, 0.24993558]\n",
            "Epoch 36 train [acc, loss]: [0.45008, 0.24420792]\n",
            "Epoch 36 val [acc, loss]: [0.4409, 0.25138336]\n",
            "Epoch 37 train [acc, loss]: [0.45576, 0.24291973]\n",
            "Epoch 37 val [acc, loss]: [0.455, 0.24747393]\n",
            "Epoch 38 train [acc, loss]: [0.45788, 0.2418976]\n",
            "Epoch 38 val [acc, loss]: [0.4592, 0.24648178]\n",
            "Epoch 39 train [acc, loss]: [0.46168, 0.24075073]\n",
            "Epoch 39 val [acc, loss]: [0.459, 0.2465773]\n",
            "Epoch 40 train [acc, loss]: [0.4669, 0.23958506]\n",
            "Epoch 40 val [acc, loss]: [0.4595, 0.244645]\n",
            "Epoch 41 train [acc, loss]: [0.47112, 0.23864017]\n",
            "Epoch 41 val [acc, loss]: [0.4669, 0.24134302]\n",
            "Epoch 42 train [acc, loss]: [0.47704, 0.23688185]\n",
            "Epoch 42 val [acc, loss]: [0.4706, 0.24050732]\n",
            "Epoch 43 train [acc, loss]: [0.48216, 0.23522793]\n",
            "Epoch 43 val [acc, loss]: [0.4725, 0.24264327]\n",
            "Epoch 44 train [acc, loss]: [0.48572, 0.23394851]\n",
            "Epoch 44 val [acc, loss]: [0.476, 0.24092427]\n",
            "Epoch 45 train [acc, loss]: [0.49038, 0.23260859]\n",
            "Epoch 45 val [acc, loss]: [0.4852, 0.23840544]\n",
            "Epoch 46 train [acc, loss]: [0.49444, 0.23129103]\n",
            "Epoch 46 val [acc, loss]: [0.4907, 0.23692146]\n",
            "Epoch 47 train [acc, loss]: [0.49864, 0.23016785]\n",
            "Epoch 47 val [acc, loss]: [0.4874, 0.23744564]\n",
            "Epoch 48 train [acc, loss]: [0.50254, 0.22917339]\n",
            "Epoch 48 val [acc, loss]: [0.4852, 0.23734894]\n",
            "Epoch 49 train [acc, loss]: [0.50588, 0.22835903]\n",
            "Epoch 49 val [acc, loss]: [0.4898, 0.23616087]\n",
            "Epoch 50 train [acc, loss]: [0.50844, 0.22744541]\n",
            "Epoch 50 val [acc, loss]: [0.4911, 0.23527363]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em06XsFT5k-8",
        "colab_type": "text"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n54OE5o016Cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dropout(input_tensor, rate, name='dropout'):\n",
        "    return tf.nn.dropout(input_tensor, rate=rate, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CuvPV55w0HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9n-Gk6zw8t-",
        "colab_type": "code",
        "outputId": "2d4d7ee9-c46e-410e-d95e-9fa4b6290e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lz8-MGY2thU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def alex_net(input_tensor, dropout_rate, num_classes):\n",
        "    with tf.variable_scope('alex_net', reuse=tf.AUTO_REUSE):\n",
        "        conv1 = conv_block(\n",
        "            input_tensor,\n",
        "            output_channels=96,\n",
        "            name='conv1',\n",
        "            kernel_size=(11, 11),\n",
        "            strides=(4, 4),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        pool1 = max_pool(\n",
        "            conv1,\n",
        "            kernel_size=(3, 3),\n",
        "            strides=(2, 2),\n",
        "            padding='VALID',\n",
        "            name='pool1'\n",
        "        )\n",
        "        conv2 = conv_block(\n",
        "            pool1,\n",
        "            name='conv2',\n",
        "            kernel_size=(5, 5),\n",
        "            output_channels=128,\n",
        "            strides=(1, 1),\n",
        "            padding='SAME'\n",
        "        )\n",
        "        pool2 = max_pool(\n",
        "            conv2,\n",
        "            kernel_size=(3, 3),\n",
        "            strides=(2, 2),\n",
        "            padding='VALID',\n",
        "            name='pool2'\n",
        "        )\n",
        "        conv3 = conv_block(\n",
        "            pool2,\n",
        "            name='conv3',\n",
        "            kernel_size=(3, 3),\n",
        "            output_channels=128,\n",
        "            strides=(1, 1),\n",
        "            padding='SAME'\n",
        "        )\n",
        "        conv4 = conv_block(\n",
        "            conv3,\n",
        "            name='conv4',\n",
        "            kernel_size=(3, 3),\n",
        "            output_channels=128,\n",
        "            strides=(1, 1),\n",
        "            padding='SAME'\n",
        "        )\n",
        "        conv5 = conv_block(\n",
        "            conv4,\n",
        "            name='conv5',\n",
        "            kernel_size=(3, 3),\n",
        "            output_channels=128,\n",
        "            strides=(1, 1),\n",
        "            padding='SAME'\n",
        "        )\n",
        "        pool5 = max_pool(\n",
        "            conv5,\n",
        "            kernel_size=(3, 3),\n",
        "            strides=(2, 2),\n",
        "            padding='VALID',\n",
        "            name='pool5'\n",
        "        )\n",
        "        \n",
        "        flattened = flatten(pool5)\n",
        "        \n",
        "        dropout1 = dropout(flattened, dropout_rate, name='dropout1')\n",
        "        \n",
        "        dense1 = dense(dropout1, 4096, name='fc1')\n",
        "        \n",
        "        dropout2 = dropout(dense1, dropout_rate, name='dropout2')\n",
        "        dense2 = dense(dropout2, 4096, name='fc2')\n",
        "        \n",
        "        logits = dense(dense2, num_classes, name='logits')\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DnteYlc34mI",
        "colab_type": "code",
        "outputId": "3701f27d-8a17-4d14-c983-a03b7f5625a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "alex_net_input = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
        "alex_net_dropout_rate = tf.placeholder(tf.float32, [])\n",
        "alex_net_logits = alex_net(alex_net_input, alex_net_dropout_rate, num_classes=5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 96\n",
            "96 128\n",
            "128 128\n",
            "128 128\n",
            "128 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJgBLf1K42jW",
        "colab_type": "code",
        "outputId": "3a934969-3957-4dd6-c5fa-e080caae9f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%time\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(alex_net_logits, feed_dict={\n",
        "    alex_net_input: np.zeros((1, 224, 224, 3)),\n",
        "    alex_net_dropout_rate: 0.5\n",
        "}).shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 52.3 ms, sys: 9.78 ms, total: 62 ms\n",
            "Wall time: 58 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNREFPos49rc",
        "colab_type": "code",
        "outputId": "fcc357f0-9ad2-4587-8f15-4d62d663e22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "alex_net_placeholder = tf.placeholder(tf.float32, [None, 224, 224, 3], name='alex_net_placeholder')\n",
        "alex_net_is_training = tf.placeholder(tf.bool, [])\n",
        "alex_net_dropout_rate = tf.placeholder(tf.float32, [])\n",
        "\n",
        "alex_net_logits = alex_net(\n",
        "    alex_net_placeholder,\n",
        "    dropout_rate=alex_net_dropout_rate,\n",
        "    num_classes=5\n",
        ")\n",
        "\n",
        "alex_net_labels_placeholder = tf.placeholder(tf.float32, [None, 5], name='alex_net_labels')\n",
        "\n",
        "\n",
        "alex_net_loss = tf.reduce_mean(\n",
        "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=alex_net_labels_placeholder,\n",
        "        logits=alex_net_logits\n",
        "    ),\n",
        "    name='alex_net_loss'\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 96\n",
            "96 128\n",
            "128 128\n",
            "128 128\n",
            "128 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3wvP_S5V0cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alex_net_predictions = tf.argmax(alex_net_logits, axis=1)\n",
        "alex_net_target = tf.argmax(alex_net_labels_placeholder, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSctTgXBWrWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alex_net_metrics = define_metrics(\n",
        "    'alex_net/metrics/',\n",
        "    variables={\n",
        "        'target': alex_net_target,\n",
        "        'predictions': alex_net_predictions,\n",
        "        'loss': alex_net_loss\n",
        "    }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBKnICJaW17f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alex_net_trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='alex_net')\n",
        "optimizer = tf.train.AdamOptimizer(\n",
        "    learning_rate=0.001\n",
        ").minimize(\n",
        "    alex_net_loss,\n",
        "    var_list=alex_net_trainable_variables\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWW71oh7W9pF",
        "colab_type": "code",
        "outputId": "b4448b05-fa38-49ad-e6c9-0c2ccc4393c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "alex_net_trainable_variables"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'alex_net/conv1/conv/weights:0' shape=(11, 11, 3, 96) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv1/conv/bias:0' shape=(96,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv2/conv/weights:0' shape=(5, 5, 96, 128) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv2/conv/bias:0' shape=(128,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv3/conv/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv3/conv/bias:0' shape=(128,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv4/conv/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv4/conv/bias:0' shape=(128,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv5/conv/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/conv5/conv/bias:0' shape=(128,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/fc1/weights:0' shape=(3200, 4096) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/fc1/bias:0' shape=(4096,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/fc2/weights:0' shape=(4096, 4096) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/fc2/bias:0' shape=(4096,) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/logits/weights:0' shape=(4096, 5) dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/logits/bias:0' shape=(5,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "018esYR2XLcj",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ml2BnPXM2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHrKX0kVXVYP",
        "colab_type": "code",
        "outputId": "835653a4-0beb-4193-d050-5c0ef6d08d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "drive.mount('/drive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp_IVM9tXarM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_FOLDER = \"/drive/My Drive/Datasets/flowers_resized\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVNK-nmVsso-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "CLASS_INDICES = {\n",
        "    class_name: index for index, class_name in enumerate(os.listdir(DATASET_FOLDER))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXy3VGSz53P",
        "colab_type": "code",
        "outputId": "ec529646-321d-4ffa-a6af-fbc20b235de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "CLASS_INDICES"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 2, 'dandelion': 0, 'rose': 4, 'sunflower': 1, 'tulip': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5ccv_6ItCUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_flower_paths():\n",
        "    paths = []\n",
        "    indices = []\n",
        "    \n",
        "    for class_name in sorted(os.listdir(DATASET_FOLDER)):\n",
        "        class_folder = os.path.join(DATASET_FOLDER, class_name)\n",
        "        \n",
        "        for filename in sorted(os.listdir(class_folder)):\n",
        "            if not filename.endswith('jpg'):\n",
        "                continue\n",
        "            path = os.path.join(class_folder, filename)\n",
        "            indices.append(CLASS_INDICES[class_name])\n",
        "            paths.append(path)\n",
        "    \n",
        "    return paths, indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyaPDizt8p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flower_paths, flower_indices = get_flower_paths()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhW5P-BJxMwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZxOkEUvxWQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flower_y = to_categorical(flower_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwhGpYdy1Jl",
        "colab_type": "code",
        "outputId": "af349534-39f9-408a-e0b9-b76123bef1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "flower_y.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vFg-w-9xZfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flower_paths_train, flower_paths_val, flower_y_train, flower_y_val = train_test_split(\n",
        "    flower_paths,\n",
        "    flower_y,\n",
        "    random_state=42,\n",
        "    test_size=0.2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l0_PPoCxhNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flower_paths_train = list(filter(lambda x: os.path.exists(x), flower_paths_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Cwu9v7xovX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flower_paths_val = list(filter(lambda x: os.path.exists(x), flower_paths_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLXs3q-0xTxM",
        "colab_type": "code",
        "outputId": "3b06a652-2b40-40d6-a499-5dbb50e4fefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "len(flower_paths_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv_ATjEJ1dvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaKi2v675O64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import Parallel, delayed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI0cM-ISC_iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def process_image(filename):\n",
        "    img = cv2.imread(filename)\n",
        "    return img / 127.5 - 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqAhLjR-5cQ9",
        "colab_type": "code",
        "outputId": "5de2a4da-c061-4857-fef1-ba7af98beb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "flowers_x_train = Parallel(n_jobs=8, verbose=10)(delayed(process_image)(path) for path in flower_paths_train)\n",
        "flowers_x_train = np.concatenate([np.expand_dims(img, 0) for img in flowers_x_train])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:   14.9s\n",
            "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:   16.9s\n",
            "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   17.9s\n",
            "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:   19.2s\n",
            "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:   20.4s\n",
            "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed:   21.5s\n",
            "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:   22.7s\n",
            "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed:   23.9s\n",
            "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed:   25.1s\n",
            "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed:   26.5s\n",
            "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   27.9s\n",
            "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed:   29.1s\n",
            "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed:   30.5s\n",
            "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed:   31.9s\n",
            "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed:   33.3s\n",
            "[Parallel(n_jobs=8)]: Done 997 tasks      | elapsed:   34.8s\n",
            "[Parallel(n_jobs=8)]: Done 1042 tasks      | elapsed:   36.4s\n",
            "[Parallel(n_jobs=8)]: Done 1089 tasks      | elapsed:   37.9s\n",
            "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed:   39.4s\n",
            "[Parallel(n_jobs=8)]: Done 1185 tasks      | elapsed:   41.0s\n",
            "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:   42.8s\n",
            "[Parallel(n_jobs=8)]: Done 1285 tasks      | elapsed:   44.5s\n",
            "[Parallel(n_jobs=8)]: Done 1336 tasks      | elapsed:   46.3s\n",
            "[Parallel(n_jobs=8)]: Done 1389 tasks      | elapsed:   48.0s\n",
            "[Parallel(n_jobs=8)]: Done 1442 tasks      | elapsed:   50.0s\n",
            "[Parallel(n_jobs=8)]: Done 1497 tasks      | elapsed:   51.7s\n",
            "[Parallel(n_jobs=8)]: Done 1552 tasks      | elapsed:   53.5s\n",
            "[Parallel(n_jobs=8)]: Done 1609 tasks      | elapsed:   55.5s\n",
            "[Parallel(n_jobs=8)]: Done 1666 tasks      | elapsed:   57.5s\n",
            "[Parallel(n_jobs=8)]: Done 1725 tasks      | elapsed:   59.4s\n",
            "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=8)]: Done 1845 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=8)]: Done 1906 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=8)]: Done 1969 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=8)]: Done 2032 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=8)]: Done 2097 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=8)]: Done 2162 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=8)]: Done 2229 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=8)]: Done 2296 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=8)]: Done 2365 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=8)]: Done 2505 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=8)]: Done 2576 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=8)]: Done 2649 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=8)]: Done 2722 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=8)]: Done 2797 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=8)]: Done 2872 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=8)]: Done 2949 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=8)]: Done 3026 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=8)]: Done 3105 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=8)]: Done 3265 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=8)]: Done 3346 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=8)]: Done 3429 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=8)]: Done 3458 out of 3458 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UW8oqgb6jVb",
        "colab_type": "code",
        "outputId": "befdd80d-6434-4fdd-b210-96ddee7a2d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "flowers_x_val = Parallel(n_jobs=8, verbose=10)(delayed(process_image)(path) for path in flower_paths_val)\n",
        "flowers_x_val = np.concatenate([np.expand_dims(img, 0) for img in flowers_x_val])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:   15.5s\n",
            "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   16.7s\n",
            "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:   17.8s\n",
            "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed:   20.0s\n",
            "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:   21.3s\n",
            "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed:   22.5s\n",
            "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed:   23.7s\n",
            "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed:   25.0s\n",
            "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   26.3s\n",
            "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed:   28.0s\n",
            "[Parallel(n_jobs=8)]: Done 865 out of 865 | elapsed:   29.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUPMP7be12dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_batches(X, y, batch_size, shuffle=True):\n",
        "    assert len(X) == len(y)\n",
        "    \n",
        "    indices = np.arange(len(X))\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    \n",
        "    for index in range(0, len(X), batch_size):\n",
        "        yield X[indices[index:index + batch_size]], y[indices[index:index + batch_size]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlkLpfphxrHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Nf87iCxu1C",
        "colab_type": "code",
        "outputId": "2e9d1c57-85bf-4070-ac93-47c5ffdfd9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "tf.local_variables()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'alex_net/metrics/train/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/train/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/train/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/train/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/val/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/val/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/val/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'alex_net/metrics/val/loss/count:0' shape=() dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WuhmOmUW_X9",
        "colab_type": "code",
        "outputId": "f295cd71-2e89-480f-b27b-20a7afe770e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch_num in range(30):\n",
        "    reset_metrics('alex_net/metrics/train')\n",
        "    reset_metrics('alex_net/metrics/val')\n",
        "    for X_batch, y_batch in iterate_batches(flowers_x_train, flower_y_train, 64):\n",
        "        \n",
        "        _, _, _, ll = sess.run([\n",
        "            optimizer,\n",
        "            alex_net_metrics['train_update_loss'],\n",
        "            alex_net_metrics['train_update_acc'],\n",
        "            alex_net_loss\n",
        "        ], feed_dict={\n",
        "            alex_net_placeholder: X_batch,\n",
        "            alex_net_labels_placeholder: y_batch,\n",
        "            alex_net_dropout_rate: 0.5\n",
        "        })\n",
        "#         print(ll)\n",
        "#         print(loss_value, accuracy)\n",
        "    \n",
        "    print(f'Epoch {epoch_num + 1} train [acc, loss]:', sess.run([\n",
        "        alex_net_metrics['train_acc'],\n",
        "        alex_net_metrics['train_loss']\n",
        "    ]))\n",
        "    \n",
        "    for X_batch, y_batch in iterate_batches(flowers_x_val, flower_y_val, 64, shuffle=False):\n",
        "        _, _ = sess.run([\n",
        "            alex_net_metrics['val_update_loss'],\n",
        "            alex_net_metrics['val_update_acc']\n",
        "        ], feed_dict = {\n",
        "            alex_net_placeholder: X_batch,\n",
        "            alex_net_labels_placeholder: y_batch,\n",
        "            alex_net_dropout_rate: 0.0\n",
        "        })\n",
        "    print(\n",
        "        f'Epoch {epoch_num + 1} val [acc, loss]:',\n",
        "        sess.run([\n",
        "            alex_net_metrics['val_acc'],\n",
        "            alex_net_metrics['val_loss']\n",
        "        ])\n",
        "    )"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train [acc, loss]: [0.23163678, 0.65364194]\n",
            "Epoch 1 val [acc, loss]: [0.2531792, 0.50296575]\n",
            "Epoch 2 train [acc, loss]: [0.23019086, 0.50425833]\n",
            "Epoch 2 val [acc, loss]: [0.28208092, 0.48282388]\n",
            "Epoch 3 train [acc, loss]: [0.26980913, 0.49187708]\n",
            "Epoch 3 val [acc, loss]: [0.28323698, 0.4893869]\n",
            "Epoch 4 train [acc, loss]: [0.2987276, 0.49007678]\n",
            "Epoch 4 val [acc, loss]: [0.30404624, 0.4807075]\n",
            "Epoch 5 train [acc, loss]: [0.29728165, 0.47487703]\n",
            "Epoch 5 val [acc, loss]: [0.33872834, 0.47995716]\n",
            "Epoch 6 train [acc, loss]: [0.3857721, 0.45324466]\n",
            "Epoch 6 val [acc, loss]: [0.39537573, 0.5010353]\n",
            "Epoch 7 train [acc, loss]: [0.4537305, 0.43031052]\n",
            "Epoch 7 val [acc, loss]: [0.3549133, 0.47957882]\n",
            "Epoch 8 train [acc, loss]: [0.45951417, 0.42228708]\n",
            "Epoch 8 val [acc, loss]: [0.50289017, 0.42467302]\n",
            "Epoch 9 train [acc, loss]: [0.47310585, 0.4144768]\n",
            "Epoch 9 val [acc, loss]: [0.47861272, 0.41729823]\n",
            "Epoch 10 train [acc, loss]: [0.52718335, 0.38885385]\n",
            "Epoch 10 val [acc, loss]: [0.5283237, 0.3788963]\n",
            "Epoch 11 train [acc, loss]: [0.5561018, 0.37776858]\n",
            "Epoch 11 val [acc, loss]: [0.48786128, 0.44259053]\n",
            "Epoch 12 train [acc, loss]: [0.56564486, 0.37134025]\n",
            "Epoch 12 val [acc, loss]: [0.5734104, 0.35387716]\n",
            "Epoch 13 train [acc, loss]: [0.597166, 0.35151199]\n",
            "Epoch 13 val [acc, loss]: [0.6034682, 0.34284687]\n",
            "Epoch 14 train [acc, loss]: [0.6029497, 0.33792412]\n",
            "Epoch 14 val [acc, loss]: [0.6046243, 0.33681855]\n",
            "Epoch 15 train [acc, loss]: [0.63909775, 0.32413208]\n",
            "Epoch 15 val [acc, loss]: [0.6069364, 0.37511852]\n",
            "Epoch 16 train [acc, loss]: [0.6451706, 0.32277468]\n",
            "Epoch 16 val [acc, loss]: [0.5653179, 0.41641527]\n",
            "Epoch 17 train [acc, loss]: [0.61451703, 0.3482872]\n",
            "Epoch 17 val [acc, loss]: [0.6138728, 0.3470927]\n",
            "Epoch 18 train [acc, loss]: [0.66743785, 0.30939505]\n",
            "Epoch 18 val [acc, loss]: [0.65202314, 0.3155718]\n",
            "Epoch 19 train [acc, loss]: [0.6321573, 0.31142277]\n",
            "Epoch 19 val [acc, loss]: [0.6450867, 0.3342633]\n",
            "Epoch 20 train [acc, loss]: [0.6726431, 0.29844007]\n",
            "Epoch 20 val [acc, loss]: [0.6427746, 0.35507074]\n",
            "Epoch 21 train [acc, loss]: [0.67582417, 0.30735838]\n",
            "Epoch 21 val [acc, loss]: [0.6092486, 0.3449413]\n",
            "Epoch 22 train [acc, loss]: [0.6182765, 0.33338454]\n",
            "Epoch 22 val [acc, loss]: [0.6462428, 0.33233172]\n",
            "Epoch 23 train [acc, loss]: [0.6830538, 0.2945332]\n",
            "Epoch 23 val [acc, loss]: [0.66936415, 0.32913923]\n",
            "Epoch 24 train [acc, loss]: [0.70156157, 0.27309632]\n",
            "Epoch 24 val [acc, loss]: [0.6485549, 0.3435099]\n",
            "Epoch 25 train [acc, loss]: [0.7284558, 0.2589634]\n",
            "Epoch 25 val [acc, loss]: [0.6901734, 0.3125368]\n",
            "Epoch 26 train [acc, loss]: [0.7301909, 0.25458848]\n",
            "Epoch 26 val [acc, loss]: [0.6473988, 0.31081015]\n",
            "Epoch 27 train [acc, loss]: [0.7414691, 0.24557997]\n",
            "Epoch 27 val [acc, loss]: [0.6971098, 0.29294735]\n",
            "Epoch 28 train [acc, loss]: [0.75506073, 0.23280767]\n",
            "Epoch 28 val [acc, loss]: [0.66705203, 0.32382736]\n",
            "Epoch 29 train [acc, loss]: [0.75506073, 0.23925515]\n",
            "Epoch 29 val [acc, loss]: [0.67398846, 0.3464958]\n",
            "Epoch 30 train [acc, loss]: [0.7432042, 0.24505216]\n",
            "Epoch 30 val [acc, loss]: [0.6763006, 0.38620323]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaCgapLlFZS7",
        "colab_type": "text"
      },
      "source": [
        "# ResNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Y7-WXtypS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def resnet_block(\n",
        "    input_tensor,\n",
        "    kernel_size,\n",
        "    filters: List[int],\n",
        "    is_training,\n",
        "    strides=(2, 2),\n",
        "    name='resnet_block'\n",
        "):\n",
        "    with tf.variable_scope(f'{name}', reuse=tf.AUTO_REUSE):\n",
        "        conv1 = conv_layer(\n",
        "            input_tensor,\n",
        "            filters[0],\n",
        "            name=f'conv1',\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "        )\n",
        "        \n",
        "        bn1, bn1_updates = batch_norm(conv1, is_training, name='bn1')\n",
        "        \n",
        "        relu1 = tf.nn.relu(bn1, name='relu1')\n",
        "        \n",
        "        \n",
        "        conv2 = conv_layer(\n",
        "            relu1,\n",
        "            filters[1],\n",
        "            name='conv2',\n",
        "            kernel_size=kernel_size,\n",
        "            strides=(1, 1)\n",
        "        )\n",
        "        \n",
        "        bn2, bn2_updates = batch_norm(conv2, is_training, name='bn2')\n",
        "        \n",
        "        \n",
        "        shortcut = conv_layer(\n",
        "            input_tensor,\n",
        "            filters[1],\n",
        "            name='shortcut',\n",
        "            kernel_size=(1, 1),\n",
        "            strides=strides\n",
        "        )\n",
        "        \n",
        "        bn_shortcut, bn_shortcut_updates = batch_norm(shortcut, is_training, name='bn_shortcut')\n",
        "        \n",
        "        \n",
        "        output = bn2 + bn_shortcut\n",
        "        \n",
        "        \n",
        "        output_activated = tf.nn.relu(output, name='relu')\n",
        "    \n",
        "    return output_activated, bn1_updates + bn2_updates + bn_shortcut_updates\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuBQvnUb65GY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNormNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.updates = []\n",
        "        self.is_training = tf.placeholder(tf.bool, shape=[])\n",
        "        \n",
        "    def add_block(self, build_fn):\n",
        "        output_tensor, output_updates = build_fn()\n",
        "        \n",
        "        self.updates.extend(output_updates)\n",
        "        return output_tensor\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP4uOewy67L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def global_average_pooling(input_tensor, name):\n",
        "    return tf.reduce_mean(input_tensor, axis=(1, 2), name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLCQ-Luq68Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.placeholder(tf.float32, [1, 32, 32, 8])\n",
        "\n",
        "b = global_average_pooling(a, name='test_global_avg_pooling')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxUaPS1L69aX",
        "colab_type": "code",
        "outputId": "9166f577-1526-4ca3-8d26-a219e7b2e9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sess.run(b, feed_dict={a: np.zeros((1, 32, 32, 8))}).shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGCwC9C06-q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet18(BatchNormNetwork):\n",
        "    \n",
        "    def __init__(self, input_tensor, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_tensor = input_tensor\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.build_network()\n",
        "    \n",
        "        \n",
        "    def build_network(self):\n",
        "        with tf.variable_scope('resnet18', reuse=tf.AUTO_REUSE):\n",
        "\n",
        "            self.block1 = self.add_block(\n",
        "                lambda: conv_block_with_bn(\n",
        "                    self.input_tensor,\n",
        "                    output_channels=64,\n",
        "                    is_training=self.is_training,\n",
        "                    name='conv1',\n",
        "                    strides=(2, 2)\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            self.resnet_block1 = self.build_resnet_block(\n",
        "                self.block1,\n",
        "                output_filters=64,\n",
        "                name='resnet_block1'\n",
        "            )\n",
        "            \n",
        "            self.resnet_block2 = self.build_resnet_block(\n",
        "                self.resnet_block1,\n",
        "                output_filters=128,\n",
        "                name='resnet_block2'\n",
        "            )\n",
        "            \n",
        "            self.resnet_block3 = self.build_resnet_block(\n",
        "                self.resnet_block2,\n",
        "                output_filters=256,\n",
        "                name='resnet_block3'\n",
        "            )\n",
        "            \n",
        "            self.resnet_block4 = self.build_resnet_block(\n",
        "                self.resnet_block3,\n",
        "                output_filters=512,\n",
        "                name='resnet_block4'\n",
        "            )\n",
        "            \n",
        "            self.avg_pool = global_average_pooling(\n",
        "                self.resnet_block4,\n",
        "                name='global_avg_pool'\n",
        "            )\n",
        "            \n",
        "            self.fc = dense(\n",
        "                self.avg_pool,\n",
        "                self.num_classes,\n",
        "                name='fc'\n",
        "            )\n",
        "            \n",
        "    def build_resnet_block(self, input_tensor, output_filters, name):\n",
        "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "            block1 = self.add_block(\n",
        "                lambda: resnet_block(\n",
        "                    input_tensor,\n",
        "                    filters=[output_filters, output_filters],\n",
        "                    name='branch1',\n",
        "                    is_training=self.is_training,\n",
        "                    strides=(2,2),\n",
        "                    kernel_size=(3, 3)\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            block2 = self.add_block(\n",
        "                lambda: resnet_block(\n",
        "                    block1,\n",
        "                    filters=[output_filters, output_filters],\n",
        "                    name='branch2',\n",
        "                    is_training=self.is_training,\n",
        "                    strides=(1, 1),\n",
        "                    kernel_size=(3, 3)\n",
        "                )\n",
        "            )\n",
        "        return block2\n",
        "    \n",
        "    def get_trainable_variables(self):\n",
        "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='resnet18')\n",
        "    \n",
        "    def get_logits(self):\n",
        "        return self.fc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E18WhUq7ARM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossMeter:\n",
        "    def __init__(self, network, inputs, labels, name):\n",
        "        self.network = network\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "        \n",
        "        self.logits = self.network.get_logits()\n",
        "        self.name = name\n",
        "        \n",
        "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "            self.loss = tf.reduce_mean(\n",
        "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                    labels=self.labels,\n",
        "                    logits=self.logits\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            self.predictions = tf.argmax(self.logits, axis=1)\n",
        "            self.target = tf.argmax(self.labels, axis=1)\n",
        "            \n",
        "            self.metrics = define_metrics(\n",
        "                f'{name}/metrics/',\n",
        "                variables={\n",
        "                    'target': self.target,\n",
        "                    'predictions': self.predictions,\n",
        "                    'loss': self.loss\n",
        "                }\n",
        "            )\n",
        "    \n",
        "            self.optimizer = tf.train.AdamOptimizer(\n",
        "                learning_rate=0.0001\n",
        "            ).minimize(\n",
        "                self.loss,\n",
        "                var_list=self.network.get_trainable_variables()\n",
        "            )\n",
        "        \n",
        "    def reset_metrics(self):\n",
        "        reset_metrics(f'{self.name}/metrics/train')\n",
        "        reset_metrics(f'{self.name}/metrics/val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEIlbXRA7Bo2",
        "colab_type": "code",
        "outputId": "22ae18d5-6570-459a-a2f3-5af39f2b9cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgmGNwLp7C_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.placeholder_with_default(np.zeros((10, 224, 224, 3), dtype=np.float32), shape=(None, 224, 224, 3))\n",
        "b = tf.placeholder_with_default(np.zeros((10, 5), dtype=np.float32), shape=(None, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_KBQk1K7Evz",
        "colab_type": "code",
        "outputId": "5f209e37-2486-405e-c9e8-c2e71390bc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "net = ResNet18(a, num_classes=5)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 64\n",
            "64 64\n",
            "64 64\n",
            "64 64\n",
            "64 64\n",
            "64 64\n",
            "64 64\n",
            "64 128\n",
            "128 128\n",
            "64 128\n",
            "128 128\n",
            "128 128\n",
            "128 128\n",
            "128 256\n",
            "256 256\n",
            "128 256\n",
            "256 256\n",
            "256 256\n",
            "256 256\n",
            "256 512\n",
            "512 512\n",
            "256 512\n",
            "512 512\n",
            "512 512\n",
            "512 512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aulhF6_d7GF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_meter = LossMeter(net, a, b, name='resnet18')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9awHql77HSz",
        "colab_type": "code",
        "outputId": "3caffdce-d44c-4d70-b64d-d61a2be96faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "tf.local_variables()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'resnet18/metrics/train/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/train/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/train/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/train/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/val/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/val/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/val/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'resnet18/metrics/val/loss/count:0' shape=() dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b2ANX9A7IbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8a678dd7-b59b-44a9-b699-282e4b0ba74d"
      },
      "source": [
        "!nproc"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqFB7rUT7Jxz",
        "colab_type": "code",
        "outputId": "d3f6c413-c1d1-4fd8-8dc6-808795a6f0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "\n",
        "for epoch_num in range(30):\n",
        "    loss_meter.reset_metrics()\n",
        "    for X_batch, y_batch in iterate_batches(flowers_x_train, flower_y_train, 64):\n",
        "        _, _, _, _ = sess.run([\n",
        "            loss_meter.optimizer,\n",
        "            loss_meter.metrics['train_update_acc'],\n",
        "            loss_meter.metrics['train_update_loss'],\n",
        "            net.updates\n",
        "        ], feed_dict={\n",
        "            loss_meter.inputs: X_batch,\n",
        "            loss_meter.labels: y_batch,\n",
        "            net.is_training: True\n",
        "        })\n",
        "        \n",
        "        loss_value, accuracy = sess.run([\n",
        "            loss_meter.metrics['train_acc'],\n",
        "            loss_meter.metrics['train_loss']\n",
        "        ])\n",
        "#         print(loss_value, accuracy)\n",
        "    \n",
        "    print(f'Epoch {epoch_num + 1} train [acc, loss]:', sess.run([\n",
        "        loss_meter.metrics['train_acc'],\n",
        "        loss_meter.metrics['train_loss']\n",
        "    ]))\n",
        "    \n",
        "    for X_batch, y_batch in iterate_batches(flowers_x_val, flower_y_val, 64, shuffle=False):\n",
        "        _, _ = sess.run([\n",
        "            loss_meter.metrics['val_update_acc'],\n",
        "            loss_meter.metrics['val_update_loss']\n",
        "        ], feed_dict = {\n",
        "            loss_meter.inputs: X_batch,\n",
        "            loss_meter.labels: y_batch,\n",
        "            net.is_training: False\n",
        "        })\n",
        "    print(\n",
        "        f'Epoch {epoch_num + 1} val [acc, loss]:',\n",
        "        sess.run([\n",
        "            loss_meter.metrics['val_acc'], \n",
        "            loss_meter.metrics['val_loss']\n",
        "        ])\n",
        "    )"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train [acc, loss]: [0.47715443, 0.42476192]\n",
            "Epoch 1 val [acc, loss]: [0.2786127, 0.5649623]\n",
            "Epoch 2 train [acc, loss]: [0.5902256, 0.3478902]\n",
            "Epoch 2 val [acc, loss]: [0.2786127, 0.86159575]\n",
            "Epoch 3 train [acc, loss]: [0.6194332, 0.33121774]\n",
            "Epoch 3 val [acc, loss]: [0.2786127, 0.8962528]\n",
            "Epoch 4 train [acc, loss]: [0.63042223, 0.32702613]\n",
            "Epoch 4 val [acc, loss]: [0.2786127, 1.0483978]\n",
            "Epoch 5 train [acc, loss]: [0.6341816, 0.32974702]\n",
            "Epoch 5 val [acc, loss]: [0.2797688, 0.8316002]\n",
            "Epoch 6 train [acc, loss]: [0.64083284, 0.32595542]\n",
            "Epoch 6 val [acc, loss]: [0.2867052, 1.064349]\n",
            "Epoch 7 train [acc, loss]: [0.64285713, 0.32021117]\n",
            "Epoch 7 val [acc, loss]: [0.3017341, 0.89284617]\n",
            "Epoch 8 train [acc, loss]: [0.6474841, 0.320752]\n",
            "Epoch 8 val [acc, loss]: [0.3479769, 0.6585222]\n",
            "Epoch 9 train [acc, loss]: [0.6376518, 0.32781297]\n",
            "Epoch 9 val [acc, loss]: [0.4647399, 0.4748876]\n",
            "Epoch 10 train [acc, loss]: [0.65442455, 0.31295115]\n",
            "Epoch 10 val [acc, loss]: [0.5653179, 0.39214614]\n",
            "Epoch 11 train [acc, loss]: [0.6474841, 0.3128526]\n",
            "Epoch 11 val [acc, loss]: [0.5387283, 0.44048318]\n",
            "Epoch 12 train [acc, loss]: [0.63736266, 0.31700763]\n",
            "Epoch 12 val [acc, loss]: [0.53757226, 0.4726552]\n",
            "Epoch 13 train [acc, loss]: [0.6445922, 0.3072525]\n",
            "Epoch 13 val [acc, loss]: [0.5364162, 0.4469018]\n",
            "Epoch 14 train [acc, loss]: [0.6440139, 0.30811927]\n",
            "Epoch 14 val [acc, loss]: [0.5549133, 0.45406193]\n",
            "Epoch 15 train [acc, loss]: [0.6506651, 0.30682784]\n",
            "Epoch 15 val [acc, loss]: [0.51560694, 0.4421939]\n",
            "Epoch 16 train [acc, loss]: [0.6683054, 0.29904193]\n",
            "Epoch 16 val [acc, loss]: [0.5768786, 0.397851]\n",
            "Epoch 17 train [acc, loss]: [0.6610758, 0.31019706]\n",
            "Epoch 17 val [acc, loss]: [0.54913294, 0.42752823]\n",
            "Epoch 18 train [acc, loss]: [0.6526894, 0.30795667]\n",
            "Epoch 18 val [acc, loss]: [0.55028903, 0.40566543]\n",
            "Epoch 19 train [acc, loss]: [0.6474841, 0.3126751]\n",
            "Epoch 19 val [acc, loss]: [0.5768786, 0.37551484]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-2864810f4776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         })\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m           if (not is_tensor_handle_feed and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5yxVG_ITkgc",
        "colab_type": "text"
      },
      "source": [
        "## Inception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5NHveTa8LQ1",
        "colab_type": "text"
      },
      "source": [
        "Основные концепции:\n",
        "\n",
        "* Используем вместо residual слоев набор слоев разного вида\n",
        "* Используем дополнительные классификаторы с меньшей функцией потерь для быстрого прохода градиентов\n",
        "* (v2+, упражнение) Даем каждому классу вероятность $\\alpha$, чтобы кросс-энтропия не скатывалась в нуль "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Eb2oIyRb0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "FilterSpec = namedtuple('FilterSpec', [\n",
        "    'filters_1x1',\n",
        "    'filters_3x3',\n",
        "    'filters_3x3_reduce',\n",
        "    'filters_5x5',\n",
        "    'filters_5x5_reduce',\n",
        "    'filters_pool'\n",
        "])\n",
        "\n",
        "\n",
        "class InceptionV1Network:\n",
        "    def __init__(self, input_tensor, num_classes):\n",
        "        self.input_tensor = input_tensor\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.build_network()\n",
        "        \n",
        "    def build_network(self):\n",
        "        with tf.variable_scope('inception_v1', reuse=tf.AUTO_REUSE):\n",
        "            self.conv1 = conv_block(\n",
        "                self.input_tensor,\n",
        "                output_channels=64,\n",
        "                name='conv1',\n",
        "                kernel_size=(7, 7),\n",
        "                strides=(2, 2)\n",
        "            )\n",
        "            \n",
        "            self.pool1 = max_pool(\n",
        "                self.conv1,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                name='pool1'\n",
        "            )\n",
        "            \n",
        "            self.conv2a = conv_block(\n",
        "                self.pool1,\n",
        "                output_channels=64,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(1, 1),\n",
        "                name='conv2a'\n",
        "            )\n",
        "            \n",
        "            self.conv2b = conv_block(\n",
        "                self.conv2a,\n",
        "                output_channels=192,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(1, 1),\n",
        "                name='conv2b'\n",
        "            )\n",
        "            \n",
        "            self.pool2 = max_pool(\n",
        "                self.conv2b,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                name='pool2'\n",
        "            )\n",
        "            \n",
        "            self.block3a = self.inception_block(\n",
        "                self.pool2,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=64,\n",
        "                    filters_3x3_reduce=96,\n",
        "                    filters_3x3=128,\n",
        "                    filters_5x5_reduce=16,\n",
        "                    filters_5x5=32,\n",
        "                    filters_pool=32,\n",
        "                ),\n",
        "                name='block3a'\n",
        "            )\n",
        "            \n",
        "            self.block3b = self.inception_block(\n",
        "                self.block3a,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=128,\n",
        "                    filters_3x3_reduce=128,\n",
        "                    filters_3x3=192,\n",
        "                    filters_5x5_reduce=32,\n",
        "                    filters_5x5=96,\n",
        "                    filters_pool=64\n",
        "                ),\n",
        "                name='block3b'\n",
        "            )\n",
        "            \n",
        "            self.pool3 = max_pool(\n",
        "                self.block3b,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                name='pool3'\n",
        "            )\n",
        "            \n",
        "            \n",
        "            self.block4a = self.inception_block(\n",
        "                self.pool3,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=192,\n",
        "                    filters_3x3_reduce=96,\n",
        "                    filters_3x3=208,\n",
        "                    filters_5x5_reduce=16,\n",
        "                    filters_5x5=48,\n",
        "                    filters_pool=64\n",
        "                ),\n",
        "                name='block4a'\n",
        "            )\n",
        "            \n",
        "            self.block4b = self.inception_block(\n",
        "                self.block4a,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=160,\n",
        "                    filters_3x3_reduce=112,\n",
        "                    filters_3x3=224,\n",
        "                    filters_5x5_reduce=24,\n",
        "                    filters_5x5=64,\n",
        "                    filters_pool=64\n",
        "                ),\n",
        "                name='block4b'\n",
        "            )\n",
        "            \n",
        "            self.block4c = self.inception_block(\n",
        "                self.block4b,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=128,\n",
        "                    filters_3x3_reduce=128,\n",
        "                    filters_3x3=256,\n",
        "                    filters_5x5_reduce=24,\n",
        "                    filters_5x5=64,\n",
        "                    filters_pool=64\n",
        "                ),\n",
        "                name='block4c'\n",
        "            )\n",
        "            \n",
        "            self.block4d = self.inception_block(\n",
        "                self.block4c,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=112,\n",
        "                    filters_3x3_reduce=144,\n",
        "                    filters_3x3=288,\n",
        "                    filters_5x5_reduce=32,\n",
        "                    filters_5x5=64,\n",
        "                    filters_pool=64\n",
        "                ),\n",
        "                name='block4d'\n",
        "            )\n",
        "            \n",
        "            self.block4e = self.inception_block(\n",
        "                self.block4d,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=256,\n",
        "                    filters_3x3_reduce=160,\n",
        "                    filters_3x3=320,\n",
        "                    filters_5x5_reduce=32,\n",
        "                    filters_5x5=128,\n",
        "                    filters_pool=128\n",
        "                ),\n",
        "                name='block4e'\n",
        "            )\n",
        "            \n",
        "            self.pool4 = max_pool(\n",
        "                self.block4e,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(2, 2),\n",
        "                name='pool4'\n",
        "            )\n",
        "            \n",
        "            self.block5a = self.inception_block(\n",
        "                self.pool4,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=256,\n",
        "                    filters_3x3_reduce=160,\n",
        "                    filters_3x3=320,\n",
        "                    filters_5x5_reduce=32,\n",
        "                    filters_5x5=128,\n",
        "                    filters_pool=128\n",
        "                ),\n",
        "                name='block5a'\n",
        "            )\n",
        "            \n",
        "            self.block5b = self.inception_block(\n",
        "                self.block5a,\n",
        "                FilterSpec(\n",
        "                    filters_1x1=384,\n",
        "                    filters_3x3_reduce=192,\n",
        "                    filters_3x3=384,\n",
        "                    filters_5x5_reduce=48,\n",
        "                    filters_5x5=128,\n",
        "                    filters_pool=128\n",
        "                ),\n",
        "                name='block5b'\n",
        "            )\n",
        "            \n",
        "            self.fc = self.build_classifier(\n",
        "                self.block5b,\n",
        "                kernel_size=(7, 7),\n",
        "                strides=(7, 7),\n",
        "                name='classifier',\n",
        "                aux=False\n",
        "            )\n",
        "            \n",
        "            self.aux1 = self.build_classifier(\n",
        "                self.block4a,\n",
        "                kernel_size=(5, 5),\n",
        "                strides=(3, 3),\n",
        "                name='aux1',\n",
        "                aux=True\n",
        "            )\n",
        "            \n",
        "            self.aux2 = self.build_classifier(\n",
        "                self.block4d,\n",
        "                kernel_size=(5, 5),\n",
        "                strides=(3, 3),\n",
        "                name='aux2',\n",
        "                aux=True\n",
        "            )\n",
        "            \n",
        "    def inception_block(self, input_tensor, filter_spec: FilterSpec, name):\n",
        "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "            conv_1x1 = conv_block(\n",
        "                input_tensor,\n",
        "                output_channels=filter_spec.filters_1x1,\n",
        "                kernel_size=(1, 1),\n",
        "                name='conv_1x1',\n",
        "            )\n",
        "            \n",
        "            conv_3x3_reduce = conv_block(\n",
        "                input_tensor,\n",
        "                output_channels=filter_spec.filters_3x3_reduce,\n",
        "                kernel_size=(1, 1),\n",
        "                name='conv_3x3_reduce',\n",
        "            )\n",
        "            \n",
        "            conv_3x3 = conv_block(\n",
        "                conv_3x3_reduce,\n",
        "                output_channels=filter_spec.filters_3x3,\n",
        "                kernel_size=(3, 3),\n",
        "                name='conv_3x3'\n",
        "            )\n",
        "            \n",
        "            conv_5x5_reduce = conv_block(\n",
        "                input_tensor,\n",
        "                output_channels=filter_spec.filters_5x5_reduce,\n",
        "                kernel_size=(1, 1),\n",
        "                name='conv_5x5_reduce'\n",
        "            )\n",
        "            \n",
        "            conv_5x5 = conv_block(\n",
        "                conv_5x5_reduce,\n",
        "                output_channels=filter_spec.filters_5x5,\n",
        "                name='conv_5x5'\n",
        "            )\n",
        "            \n",
        "            pool_reduce = max_pool(\n",
        "                input_tensor,\n",
        "                kernel_size=(3, 3),\n",
        "                strides=(1, 1),\n",
        "                name='pool_reduce'\n",
        "            )\n",
        "            \n",
        "            pool = conv_block(\n",
        "                pool_reduce,\n",
        "                output_channels=filter_spec.filters_pool,\n",
        "                name='pool'\n",
        "            )\n",
        "            \n",
        "            output = tf.concat(\n",
        "                [conv_1x1, conv_3x3, conv_5x5, pool],\n",
        "                axis=3, \n",
        "                name='concat'\n",
        "            )\n",
        "        return output\n",
        "    \n",
        "    def build_classifier(self, input_tensor, kernel_size, strides, name, aux=True):\n",
        "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "            pool = avg_pool(\n",
        "                input_tensor,\n",
        "                kernel_size=kernel_size,\n",
        "                strides=strides,\n",
        "                name='pool'\n",
        "            )\n",
        "            \n",
        "            if aux:\n",
        "                conv = conv_block(\n",
        "                    pool,\n",
        "                    output_channels=128,\n",
        "                    kernel_size=(1, 1),\n",
        "                    strides=(1, 1),\n",
        "                    name='conv'\n",
        "                )\n",
        "                \n",
        "                flatten_out = flatten(conv)\n",
        "                \n",
        "                fc1 = dense(flatten_out, 1024, name='fc1')\n",
        "                relu1 = tf.nn.relu(fc1, name='relu1')\n",
        "                \n",
        "                fc = dense(relu1, self.num_classes, name='fc')\n",
        "                \n",
        "            else:\n",
        "                flatten_out = flatten(pool)\n",
        "                fc = dense(flatten_out, self.num_classes, name='fc')\n",
        "            \n",
        "            return fc\n",
        "     \n",
        "    def get_logits(self):\n",
        "        return self.fc\n",
        "    \n",
        "    def get_trainable_variables(self):\n",
        "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='inception_v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nfsJAX-T8D-",
        "colab_type": "code",
        "outputId": "1f7a2883-74f2-43c4-9c0e-70f9bf9c6232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSFFUfYnUJUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.placeholder_with_default(np.zeros((10, 224, 224, 3), dtype=np.float32), shape=(None, 224, 224, 3))\n",
        "b = tf.placeholder_with_default(np.zeros((10, 5), dtype=np.float32), shape=(None, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twa_PkuJYl5f",
        "colab_type": "code",
        "outputId": "3292f22c-513d-4644-982d-0f432e12c916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "net = InceptionV1Network(a, num_classes=5)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 64\n",
            "64 64\n",
            "64 192\n",
            "192 64\n",
            "192 96\n",
            "96 128\n",
            "192 16\n",
            "16 32\n",
            "192 32\n",
            "256 128\n",
            "256 128\n",
            "128 192\n",
            "256 32\n",
            "32 96\n",
            "256 64\n",
            "480 192\n",
            "480 96\n",
            "96 208\n",
            "480 16\n",
            "16 48\n",
            "480 64\n",
            "512 160\n",
            "512 112\n",
            "112 224\n",
            "512 24\n",
            "24 64\n",
            "512 64\n",
            "512 128\n",
            "512 128\n",
            "128 256\n",
            "512 24\n",
            "24 64\n",
            "512 64\n",
            "512 112\n",
            "512 144\n",
            "144 288\n",
            "512 32\n",
            "32 64\n",
            "512 64\n",
            "528 256\n",
            "528 160\n",
            "160 320\n",
            "528 32\n",
            "32 128\n",
            "528 128\n",
            "832 256\n",
            "832 160\n",
            "160 320\n",
            "832 32\n",
            "32 128\n",
            "832 128\n",
            "832 384\n",
            "832 192\n",
            "192 384\n",
            "832 48\n",
            "48 128\n",
            "832 128\n",
            "512 128\n",
            "528 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7mkvZNAYtMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMeVFVIRY-GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossMeterInception:\n",
        "    def __init__(self, network, inputs, labels, name):\n",
        "        self.network = network\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "        \n",
        "        self.logits = self.network.get_logits()\n",
        "        self.name = name\n",
        "        \n",
        "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "            self.loss = tf.reduce_mean(\n",
        "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                    labels=self.labels,\n",
        "                    logits=self.logits\n",
        "                )\n",
        "            ) + 0.3 * tf.reduce_mean(\n",
        "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                    labels=self.labels,\n",
        "                    logits=self.network.aux1\n",
        "                )\n",
        "            ) + 0.3 * tf.reduce_mean(\n",
        "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                    labels=self.labels,\n",
        "                    logits=self.network.aux2\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            self.predictions = tf.argmax(self.logits, axis=1)\n",
        "            self.target = tf.argmax(self.labels, axis=1)\n",
        "            \n",
        "            self.metrics = define_metrics(\n",
        "                f'{name}/metrics/',\n",
        "                variables={\n",
        "                    'target': self.target,\n",
        "                    'predictions': self.predictions,\n",
        "                    'loss': self.loss\n",
        "                }\n",
        "            )\n",
        "    \n",
        "            self.optimizer = tf.train.AdamOptimizer(\n",
        "                learning_rate=0.0001\n",
        "            ).minimize(\n",
        "                self.loss,\n",
        "                var_list=self.network.get_trainable_variables()\n",
        "            )\n",
        "        \n",
        "    def reset_metrics(self):\n",
        "        reset_metrics(f'{self.name}/metrics/train')\n",
        "        reset_metrics(f'{self.name}/metrics/val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDC_zcT4fJyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_meter = LossMeterInception(net, a, b, name='inception_v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLr_YOtfR2-",
        "colab_type": "code",
        "outputId": "941eec97-8bc1-4369-da1d-4eac57b4bb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "\n",
        "for epoch_num in range(30):\n",
        "    loss_meter.reset_metrics()\n",
        "    for X_batch, y_batch in iterate_batches(flowers_x_train, flower_y_train, 64):\n",
        "        _, _, _ = sess.run([\n",
        "            loss_meter.optimizer,\n",
        "            loss_meter.metrics['train_update_acc'],\n",
        "            loss_meter.metrics['train_update_loss']\n",
        "        ], feed_dict={\n",
        "            loss_meter.inputs: X_batch,\n",
        "            loss_meter.labels: y_batch\n",
        "        })\n",
        "        \n",
        "        loss_value, accuracy = sess.run([\n",
        "            loss_meter.metrics['train_acc'],\n",
        "            loss_meter.metrics['train_loss']\n",
        "        ])\n",
        "#         print(loss_value, accuracy)\n",
        "    \n",
        "    print(f'Epoch {epoch_num + 1} train [acc, loss]:', sess.run([\n",
        "        loss_meter.metrics['train_acc'],\n",
        "        loss_meter.metrics['train_loss']\n",
        "    ]))\n",
        "    \n",
        "    for X_batch, y_batch in iterate_batches(flowers_x_val, flower_y_val, 64, shuffle=False):\n",
        "        _, _ = sess.run([\n",
        "            loss_meter.metrics['val_update_acc'],\n",
        "            loss_meter.metrics['val_update_loss']\n",
        "        ], feed_dict = {\n",
        "            loss_meter.inputs: X_batch,\n",
        "            loss_meter.labels: y_batch,\n",
        "        })\n",
        "    print(\n",
        "        f'Epoch {epoch_num + 1} val [acc, loss]:',\n",
        "        sess.run([\n",
        "            loss_meter.metrics['val_acc'], \n",
        "            loss_meter.metrics['val_loss']\n",
        "        ])\n",
        "    )"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train [acc, loss]: [0.22151533, 0.84626544]\n",
            "Epoch 1 val [acc, loss]: [0.20462428, 0.80351466]\n",
            "Epoch 2 train [acc, loss]: [0.3039329, 0.7399973]\n",
            "Epoch 2 val [acc, loss]: [0.3583815, 0.70096]\n",
            "Epoch 3 train [acc, loss]: [0.43001735, 0.637465]\n",
            "Epoch 3 val [acc, loss]: [0.4231214, 0.6336546]\n",
            "Epoch 4 train [acc, loss]: [0.4612493, 0.6044609]\n",
            "Epoch 4 val [acc, loss]: [0.38034683, 0.7307488]\n",
            "Epoch 5 train [acc, loss]: [0.4569115, 0.6113557]\n",
            "Epoch 5 val [acc, loss]: [0.46127167, 0.6256698]\n",
            "Epoch 6 train [acc, loss]: [0.5127241, 0.5815573]\n",
            "Epoch 6 val [acc, loss]: [0.48901734, 0.59670895]\n",
            "Epoch 7 train [acc, loss]: [0.5433777, 0.5421281]\n",
            "Epoch 7 val [acc, loss]: [0.50057805, 0.64253205]\n",
            "Epoch 8 train [acc, loss]: [0.61538464, 0.5027179]\n",
            "Epoch 8 val [acc, loss]: [0.48901734, 0.65638846]\n",
            "Epoch 9 train [acc, loss]: [0.60179293, 0.5070995]\n",
            "Epoch 9 val [acc, loss]: [0.5919075, 0.5451559]\n",
            "Epoch 10 train [acc, loss]: [0.6486408, 0.46504346]\n",
            "Epoch 10 val [acc, loss]: [0.66589594, 0.47146264]\n",
            "Epoch 11 train [acc, loss]: [0.6657027, 0.44786003]\n",
            "Epoch 11 val [acc, loss]: [0.6115607, 0.6139446]\n",
            "Epoch 12 train [acc, loss]: [0.64979756, 0.4620152]\n",
            "Epoch 12 val [acc, loss]: [0.65549135, 0.5082115]\n",
            "Epoch 13 train [acc, loss]: [0.6813187, 0.45160103]\n",
            "Epoch 13 val [acc, loss]: [0.66589594, 0.49092674]\n",
            "Epoch 14 train [acc, loss]: [0.69895893, 0.43183848]\n",
            "Epoch 14 val [acc, loss]: [0.72138727, 0.43408877]\n",
            "Epoch 15 train [acc, loss]: [0.7238288, 0.39795995]\n",
            "Epoch 15 val [acc, loss]: [0.6924856, 0.44402]\n",
            "Epoch 16 train [acc, loss]: [0.72093695, 0.3993722]\n",
            "Epoch 16 val [acc, loss]: [0.70751446, 0.43855104]\n",
            "Epoch 17 train [acc, loss]: [0.7371313, 0.38178027]\n",
            "Epoch 17 val [acc, loss]: [0.7144509, 0.41364452]\n",
            "Epoch 18 train [acc, loss]: [0.75072294, 0.35503888]\n",
            "Epoch 18 val [acc, loss]: [0.7098266, 0.43972692]\n",
            "Epoch 19 train [acc, loss]: [0.7495662, 0.3571307]\n",
            "Epoch 19 val [acc, loss]: [0.7317919, 0.41837218]\n",
            "Epoch 20 train [acc, loss]: [0.7582418, 0.36159602]\n",
            "Epoch 20 val [acc, loss]: [0.72023124, 0.42609134]\n",
            "Epoch 21 train [acc, loss]: [0.7443609, 0.3576824]\n",
            "Epoch 21 val [acc, loss]: [0.74104047, 0.40309817]\n",
            "Epoch 22 train [acc, loss]: [0.7865818, 0.33340007]\n",
            "Epoch 22 val [acc, loss]: [0.75606936, 0.3962304]\n",
            "Epoch 23 train [acc, loss]: [0.7741469, 0.3309469]\n",
            "Epoch 23 val [acc, loss]: [0.7549133, 0.3906109]\n",
            "Epoch 24 train [acc, loss]: [0.80277616, 0.30652043]\n",
            "Epoch 24 val [acc, loss]: [0.6971098, 0.5011263]\n",
            "Epoch 25 train [acc, loss]: [0.7634471, 0.35387364]\n",
            "Epoch 25 val [acc, loss]: [0.72138727, 0.4603488]\n",
            "Epoch 26 train [acc, loss]: [0.80335456, 0.29645404]\n",
            "Epoch 26 val [acc, loss]: [0.7456647, 0.3960357]\n",
            "Epoch 27 train [acc, loss]: [0.816657, 0.27583227]\n",
            "Epoch 27 val [acc, loss]: [0.7144509, 0.4568543]\n",
            "Epoch 28 train [acc, loss]: [0.8019086, 0.2924788]\n",
            "Epoch 28 val [acc, loss]: [0.716763, 0.4613226]\n",
            "Epoch 29 train [acc, loss]: [0.8149219, 0.27849436]\n",
            "Epoch 29 val [acc, loss]: [0.7479769, 0.4280438]\n",
            "Epoch 30 train [acc, loss]: [0.83082706, 0.26229832]\n",
            "Epoch 30 val [acc, loss]: [0.7734104, 0.36242387]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5P3rXbz89oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FObU97ea8-Dp",
        "colab_type": "text"
      },
      "source": [
        "# Упражнения\n",
        "\n",
        "* Примените методику аугментаций для тренировочного сета. Изменилось ли качество полученных сетей?\n",
        "\n",
        "* batch normalization не дает четкой картины сходимости, попробуйте построить в tensorboard гистограммы сходимостей распределения векторов `moving_mean` и `moving_var`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNGHvBbQ1QlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}